{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e1539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running simulations for lambda = 10...\n",
      "\n",
      "Strategy: EW (lambda = 10)\n",
      "Annualized Return: Mean = 0.1228, Std = 0.0338\n",
      "Cumulative Return: Mean = 0.6276, Std = 0.2258\n",
      "Volatility: Mean = 0.0792, Std = 0.0048\n",
      "Downside Deviation: Mean = 0.0470, Std = 0.0034\n",
      "Max Drawdown: Mean = -0.0946, Std = 0.0306\n",
      "Sharpe Ratio: Mean = 1.5541, Std = 0.4304\n",
      "Sortino Ratio: Mean = 2.6308, Std = 0.7540\n",
      "Calmar Ratio: Mean = 1.5287, Std = 0.7944\n",
      "Turnover Rate: Mean = 0.0000, Std = 0.0000\n",
      "\n",
      "Strategy: SJM-BL (lambda = 10)\n",
      "Annualized Return: Mean = 0.1349, Std = 0.0333\n",
      "Cumulative Return: Mean = 0.7069, Std = 0.2261\n",
      "Volatility: Mean = 0.0808, Std = 0.0041\n",
      "Downside Deviation: Mean = 0.0484, Std = 0.0032\n",
      "Max Drawdown: Mean = -0.0908, Std = 0.0301\n",
      "Sharpe Ratio: Mean = 1.6643, Std = 0.3753\n",
      "Sortino Ratio: Mean = 2.7832, Std = 0.6583\n",
      "Calmar Ratio: Mean = 1.6924, Std = 0.7198\n",
      "Turnover Rate: Mean = 0.0041, Std = 0.0008\n",
      "\n",
      "Running simulations for lambda = 25...\n",
      "\n",
      "Strategy: EW (lambda = 25)\n",
      "Annualized Return: Mean = 0.1228, Std = 0.0338\n",
      "Cumulative Return: Mean = 0.6276, Std = 0.2258\n",
      "Volatility: Mean = 0.0792, Std = 0.0048\n",
      "Downside Deviation: Mean = 0.0470, Std = 0.0034\n",
      "Max Drawdown: Mean = -0.0946, Std = 0.0306\n",
      "Sharpe Ratio: Mean = 1.5541, Std = 0.4304\n",
      "Sortino Ratio: Mean = 2.6308, Std = 0.7540\n",
      "Calmar Ratio: Mean = 1.5287, Std = 0.7944\n",
      "Turnover Rate: Mean = 0.0000, Std = 0.0000\n",
      "\n",
      "Strategy: SJM-BL (lambda = 25)\n",
      "Annualized Return: Mean = 0.1336, Std = 0.0317\n",
      "Cumulative Return: Mean = 0.6966, Std = 0.2144\n",
      "Volatility: Mean = 0.0811, Std = 0.0047\n",
      "Downside Deviation: Mean = 0.0484, Std = 0.0036\n",
      "Max Drawdown: Mean = -0.0950, Std = 0.0301\n",
      "Sharpe Ratio: Mean = 1.6447, Std = 0.3606\n",
      "Sortino Ratio: Mean = 2.7597, Std = 0.6215\n",
      "Calmar Ratio: Mean = 1.6150, Std = 0.7315\n",
      "Turnover Rate: Mean = 0.0038, Std = 0.0008\n",
      "\n",
      "Running simulations for lambda = 50...\n",
      "\n",
      "Strategy: EW (lambda = 50)\n",
      "Annualized Return: Mean = 0.1228, Std = 0.0338\n",
      "Cumulative Return: Mean = 0.6276, Std = 0.2258\n",
      "Volatility: Mean = 0.0792, Std = 0.0048\n",
      "Downside Deviation: Mean = 0.0470, Std = 0.0034\n",
      "Max Drawdown: Mean = -0.0946, Std = 0.0306\n",
      "Sharpe Ratio: Mean = 1.5541, Std = 0.4304\n",
      "Sortino Ratio: Mean = 2.6308, Std = 0.7540\n",
      "Calmar Ratio: Mean = 1.5287, Std = 0.7944\n",
      "Turnover Rate: Mean = 0.0000, Std = 0.0000\n",
      "\n",
      "Strategy: SJM-BL (lambda = 50)\n",
      "Annualized Return: Mean = 0.1346, Std = 0.0330\n",
      "Cumulative Return: Mean = 0.7042, Std = 0.2262\n",
      "Volatility: Mean = 0.0810, Std = 0.0050\n",
      "Downside Deviation: Mean = 0.0485, Std = 0.0038\n",
      "Max Drawdown: Mean = -0.0924, Std = 0.0277\n",
      "Sharpe Ratio: Mean = 1.6571, Std = 0.3711\n",
      "Sortino Ratio: Mean = 2.7732, Std = 0.6403\n",
      "Calmar Ratio: Mean = 1.6464, Std = 0.7104\n",
      "Turnover Rate: Mean = 0.0037, Std = 0.0010\n",
      "\n",
      "Running simulations for lambda = 75...\n",
      "\n",
      "Strategy: EW (lambda = 75)\n",
      "Annualized Return: Mean = 0.1228, Std = 0.0338\n",
      "Cumulative Return: Mean = 0.6276, Std = 0.2258\n",
      "Volatility: Mean = 0.0792, Std = 0.0048\n",
      "Downside Deviation: Mean = 0.0470, Std = 0.0034\n",
      "Max Drawdown: Mean = -0.0946, Std = 0.0306\n",
      "Sharpe Ratio: Mean = 1.5541, Std = 0.4304\n",
      "Sortino Ratio: Mean = 2.6308, Std = 0.7540\n",
      "Calmar Ratio: Mean = 1.5287, Std = 0.7944\n",
      "Turnover Rate: Mean = 0.0000, Std = 0.0000\n",
      "\n",
      "Strategy: SJM-BL (lambda = 75)\n",
      "Annualized Return: Mean = 0.1328, Std = 0.0346\n",
      "Cumulative Return: Mean = 0.6938, Std = 0.2341\n",
      "Volatility: Mean = 0.0811, Std = 0.0047\n",
      "Downside Deviation: Mean = 0.0486, Std = 0.0034\n",
      "Max Drawdown: Mean = -0.0940, Std = 0.0260\n",
      "Sharpe Ratio: Mean = 1.6310, Std = 0.3862\n",
      "Sortino Ratio: Mean = 2.7309, Std = 0.6669\n",
      "Calmar Ratio: Mean = 1.5864, Std = 0.6904\n",
      "Turnover Rate: Mean = 0.0035, Std = 0.0011\n",
      "\n",
      "Running simulations for lambda = 100...\n",
      "\n",
      "Strategy: EW (lambda = 100)\n",
      "Annualized Return: Mean = 0.1228, Std = 0.0338\n",
      "Cumulative Return: Mean = 0.6276, Std = 0.2258\n",
      "Volatility: Mean = 0.0792, Std = 0.0048\n",
      "Downside Deviation: Mean = 0.0470, Std = 0.0034\n",
      "Max Drawdown: Mean = -0.0946, Std = 0.0306\n",
      "Sharpe Ratio: Mean = 1.5541, Std = 0.4304\n",
      "Sortino Ratio: Mean = 2.6308, Std = 0.7540\n",
      "Calmar Ratio: Mean = 1.5287, Std = 0.7944\n",
      "Turnover Rate: Mean = 0.0000, Std = 0.0000\n",
      "\n",
      "Strategy: SJM-BL (lambda = 100)\n",
      "Annualized Return: Mean = 0.1326, Std = 0.0334\n",
      "Cumulative Return: Mean = 0.6907, Std = 0.2234\n",
      "Volatility: Mean = 0.0813, Std = 0.0047\n",
      "Downside Deviation: Mean = 0.0487, Std = 0.0033\n",
      "Max Drawdown: Mean = -0.0950, Std = 0.0255\n",
      "Sharpe Ratio: Mean = 1.6246, Std = 0.3728\n",
      "Sortino Ratio: Mean = 2.7186, Std = 0.6419\n",
      "Calmar Ratio: Mean = 1.5664, Std = 0.6877\n",
      "Turnover Rate: Mean = 0.0033, Std = 0.0009\n",
      "\n",
      "Running simulations for lambda = 125...\n",
      "\n",
      "Strategy: EW (lambda = 125)\n",
      "Annualized Return: Mean = 0.1228, Std = 0.0338\n",
      "Cumulative Return: Mean = 0.6276, Std = 0.2258\n",
      "Volatility: Mean = 0.0792, Std = 0.0048\n",
      "Downside Deviation: Mean = 0.0470, Std = 0.0034\n",
      "Max Drawdown: Mean = -0.0946, Std = 0.0306\n",
      "Sharpe Ratio: Mean = 1.5541, Std = 0.4304\n",
      "Sortino Ratio: Mean = 2.6308, Std = 0.7540\n",
      "Calmar Ratio: Mean = 1.5287, Std = 0.7944\n",
      "Turnover Rate: Mean = 0.0000, Std = 0.0000\n",
      "\n",
      "Strategy: SJM-BL (lambda = 125)\n",
      "Annualized Return: Mean = 0.1312, Std = 0.0328\n",
      "Cumulative Return: Mean = 0.6803, Std = 0.2177\n",
      "Volatility: Mean = 0.0818, Std = 0.0050\n",
      "Downside Deviation: Mean = 0.0490, Std = 0.0032\n",
      "Max Drawdown: Mean = -0.0992, Std = 0.0257\n",
      "Sharpe Ratio: Mean = 1.5959, Std = 0.3583\n",
      "Sortino Ratio: Mean = 2.6682, Std = 0.6149\n",
      "Calmar Ratio: Mean = 1.4753, Std = 0.6340\n",
      "Turnover Rate: Mean = 0.0028, Std = 0.0010\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# PyPortfolioOpt\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt.black_litterman import BlackLittermanModel\n",
    "\n",
    "# For the SJM (Sparse Jump Model)\n",
    "from jumpmodels.sparse_jump import SparseJumpModel\n",
    "from jumpmodels.preprocess import StandardScalerPD, DataClipperStd\n",
    "\n",
    "ASSETS = [\"Value\", \"Growth\", \"LowVol\", \"Size\", \"Momentum\", \"Quality\"]\n",
    "N_ASSETS = len(ASSETS)\n",
    "\n",
    "# --- 1. Data simulation (2-state only) ---\n",
    "def simulate_2state_data(num_days, seed=None):\n",
    "    \"\"\"\n",
    "    Simulates a returns DataFrame with shape (num_days, N_ASSETS),\n",
    "    plus a separate matrix of hidden states. Returns (DataFrame, states).\n",
    "    \"\"\"\n",
    "    np_rng = np.random.default_rng(seed)\n",
    "    transmat = np.array([\n",
    "        [0.9976, 0.0024],\n",
    "        [0.0232, 0.9768]\n",
    "    ])\n",
    "    mu_dict  = {0: 0.0006,   1: -0.000881}\n",
    "    sig_dict = {0: 0.00757,  1: 0.0163}\n",
    "    base_corr = np.full((N_ASSETS, N_ASSETS), 0.185)\n",
    "    np.fill_diagonal(base_corr, 1.0)\n",
    "\n",
    "    # Edge check\n",
    "    if num_days < 1:\n",
    "        raise ValueError(\"num_days must be >= 1.\")\n",
    "\n",
    "    # Simulate each asset's hidden states\n",
    "    all_states = np.zeros((num_days, N_ASSETS), dtype=int)\n",
    "    for i in range(N_ASSETS):\n",
    "        s = np.zeros(num_days, dtype=int)\n",
    "        s[0] = np_rng.integers(2)\n",
    "        for t in range(1, num_days):\n",
    "            s[t] = np_rng.choice(2, p=transmat[s[t - 1]])\n",
    "        all_states[:, i] = s\n",
    "\n",
    "    # Generate returns\n",
    "    rets = np.zeros((num_days, N_ASSETS))\n",
    "    for t in range(num_days):\n",
    "        mu_vec  = np.zeros(N_ASSETS)\n",
    "        sig_vec = np.zeros(N_ASSETS)\n",
    "        for i in range(N_ASSETS):\n",
    "            curr_state = all_states[t, i]\n",
    "            mu_vec[i]  = mu_dict[curr_state]\n",
    "            sig_vec[i] = sig_dict[curr_state]\n",
    "        cov_t = np.outer(sig_vec, sig_vec) * base_corr\n",
    "        rets[t] = np_rng.multivariate_normal(mean=mu_vec, cov=cov_t)\n",
    "\n",
    "    return pd.DataFrame(rets, columns=ASSETS), all_states\n",
    "\n",
    "\n",
    "# --- 2. SJM functions ---\n",
    "def compute_sjm_features(factor_ser: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create SJM features (downside dev, differences of dev, etc.).\n",
    "    \"\"\"\n",
    "    def ewm_downside_dev(returns: pd.Series, halflife: float) -> pd.Series:\n",
    "        negative_returns = returns.clip(upper=0)\n",
    "        neg_sq = negative_returns ** 2\n",
    "        ewm_mean = neg_sq.ewm(halflife=halflife, adjust=False).mean()\n",
    "        return np.sqrt(ewm_mean)\n",
    "\n",
    "    dd20 = ewm_downside_dev(factor_ser, halflife=20)\n",
    "    dd60 = ewm_downside_dev(factor_ser, halflife=60)\n",
    "    dd120 = ewm_downside_dev(factor_ser, halflife=120)\n",
    "\n",
    "    feats = {\n",
    "        \"DD_hl20\": dd20,\n",
    "        \"DD20_minus_DD60\": dd20 - dd60,\n",
    "        \"DD60_minus_DD120\": dd60 - dd120,\n",
    "        \"Return_hl120\": factor_ser.ewm(halflife=120, adjust=False).mean(),\n",
    "    }\n",
    "    df_feats = pd.DataFrame(feats).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return df_feats\n",
    "\n",
    "def train_sjm_single_asset(series, n_components=2, max_feats=4, lam=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Trains a SparseJumpModel on one asset's returns and returns\n",
    "    the fitted model plus the transformations.\n",
    "    \"\"\"\n",
    "    # Quick check to ensure enough data\n",
    "    if len(series) < 2:\n",
    "        raise ValueError(\"Not enough data points to train the SJM on a single asset.\")\n",
    "\n",
    "    feats_df = compute_sjm_features(series)\n",
    "    clipper = DataClipperStd(mul=3.0)\n",
    "    scaler  = StandardScalerPD()\n",
    "    X_clipped = clipper.fit_transform(feats_df)\n",
    "    X_scaled  = scaler.fit_transform(X_clipped)\n",
    "    X_arr = X_scaled.values\n",
    "\n",
    "    sjm = SparseJumpModel(\n",
    "        n_components=n_components,\n",
    "        max_feats=max_feats,\n",
    "        jump_penalty=lam,\n",
    "        cont=False,\n",
    "        max_iter=20,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    sjm.fit(X_arr)\n",
    "    return sjm, clipper, scaler\n",
    "\n",
    "def get_regime_means_stds_single_asset(asset_series, regime_assignments):\n",
    "    \"\"\"\n",
    "    Computes the mean and std for each regime in 'regime_assignments'.\n",
    "    \"\"\"\n",
    "    unique_states = np.unique(regime_assignments)\n",
    "    regime_means = {}\n",
    "    regime_stds  = {}\n",
    "    for s in unique_states:\n",
    "        data_in_s = asset_series[regime_assignments == s]\n",
    "        if len(data_in_s) > 0:\n",
    "            regime_means[s] = data_in_s.mean()\n",
    "            regime_stds[s]  = data_in_s.std()\n",
    "        else:\n",
    "            # Fallback if no points in that regime\n",
    "            regime_means[s] = asset_series.mean()\n",
    "            regime_stds[s]  = asset_series.std()\n",
    "    return regime_means, regime_stds\n",
    "\n",
    "\n",
    "# --- 3. Black-Litterman helper functions ---\n",
    "def build_equal_unconditional_prior(df_train):\n",
    "    \"\"\"\n",
    "    Returns a simple unconditional prior vector and covariance matrix\n",
    "    based on the single-state simulation assumptions.\n",
    "    \"\"\"\n",
    "    SIM_MEAN_1STATE = 0.000461\n",
    "    SIM_SIG_1STATE  = 0.008388\n",
    "    TRUE_CORR       = 0.185\n",
    "\n",
    "    n_assets = df_train.shape[1]\n",
    "    uniform_corr = np.full((n_assets, n_assets), TRUE_CORR)\n",
    "    np.fill_diagonal(uniform_corr, 1.0)\n",
    "    cov_flat = (SIM_SIG_1STATE**2) * uniform_corr\n",
    "\n",
    "    assets = df_train.columns\n",
    "    pi_series = pd.Series(np.full(n_assets, SIM_MEAN_1STATE), index=assets)\n",
    "    cov_df = pd.DataFrame(cov_flat, index=assets, columns=assets)\n",
    "    return pi_series, cov_df\n",
    "\n",
    "def get_rolling_cov(full_returns, current_index, halflife=126):\n",
    "    \"\"\"\n",
    "    Returns an exponentially weighted covariance matrix up to row 'current_index'.\n",
    "    \"\"\"\n",
    "    sub_df = full_returns.iloc[:current_index]\n",
    "    if len(sub_df) < 2:\n",
    "        # Fallback to identity if too little data\n",
    "        n_ = sub_df.shape[1]\n",
    "        return np.eye(n_)\n",
    "    span_equiv = (2 / (1 - np.exp(-np.log(2) / halflife))) - 1\n",
    "    cov_est = risk_models.exp_cov(sub_df, span=span_equiv, returns_data=True)\n",
    "    return cov_est\n",
    "\n",
    "def regime_based_bl_backtest_flatprior(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    states_test,\n",
    "    init_state,\n",
    "    regime_means_list,\n",
    "    transaction_cost=0.0007,\n",
    "    risk_free_rate=0.02/252,\n",
    "    bl_tau=0.05,\n",
    "    halflife=126\n",
    "):\n",
    "    \"\"\"\n",
    "    A BL backtest that rebalances only when regime changes.\n",
    "    \"\"\"\n",
    "    T_test = len(df_test)\n",
    "    assets = df_test.columns\n",
    "    n_assets = len(assets)\n",
    "    combined_df = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Build an unconditional prior (not used heavily except for structure)\n",
    "    flat_pi, _ = build_equal_unconditional_prior(df_train)\n",
    "\n",
    "    portfolio_vals = np.zeros(T_test)\n",
    "    if T_test == 0:\n",
    "        # If no test data, just return empty arrays\n",
    "        return portfolio_vals, np.zeros((0, n_assets)), []\n",
    "\n",
    "    portfolio_vals[0] = 1.0\n",
    "    weight_history = np.zeros((T_test, n_assets))\n",
    "\n",
    "    # Start with equal weights\n",
    "    w_prev = np.ones(n_assets) / n_assets\n",
    "    weight_history[0] = w_prev\n",
    "\n",
    "    fallback_records = []\n",
    "\n",
    "    for t in range(1, T_test):\n",
    "        # Growth from previous day\n",
    "        ret_t_minus_1 = df_test.iloc[t - 1].values\n",
    "        gross_growth = portfolio_vals[t - 1] * (1.0 + np.dot(w_prev, ret_t_minus_1))\n",
    "\n",
    "        # Check regime change\n",
    "        if t == 1:\n",
    "            current_states = init_state\n",
    "            do_rebalance = True\n",
    "        else:\n",
    "            current_states = states_test[t - 1]\n",
    "            do_rebalance = np.any(states_test[t - 1] != states_test[t - 2])\n",
    "\n",
    "        if do_rebalance:\n",
    "            # Build absolute views from regime_means\n",
    "            view_vector = np.zeros(n_assets)\n",
    "            for i in range(n_assets):\n",
    "                view_vector[i] = regime_means_list[i].get(current_states[i], 0.0)\n",
    "\n",
    "            # Rolling cov up to (train + t)\n",
    "            global_index = len(df_train) + t\n",
    "            cov_t = get_rolling_cov(combined_df, global_index, halflife=halflife)\n",
    "\n",
    "            # Build the BL model\n",
    "            bl = BlackLittermanModel(\n",
    "                cov_matrix=cov_t,\n",
    "                pi=\"equal\",\n",
    "                absolute_views=dict(zip(assets, view_vector)),\n",
    "                tau=bl_tau,\n",
    "                risk_aversion=2.5\n",
    "            )\n",
    "            # Posterior returns\n",
    "            bl_rets = bl.bl_returns()\n",
    "\n",
    "            # Solve the EF with max_sharpe\n",
    "            ef = EfficientFrontier(bl_rets, cov_t, weight_bounds=(0, 1), solver=\"SCS\")\n",
    "            try:\n",
    "                w_dict = ef.max_sharpe(risk_free_rate=risk_free_rate)\n",
    "            except ValueError as e:\n",
    "                # Fallback to equal-weight if solver fails\n",
    "                fallback_records.append({\n",
    "                    \"time\": t,\n",
    "                    \"predicted_regime\": current_states.copy(),\n",
    "                    \"absolute_views\": dict(zip(assets, view_vector)),\n",
    "                    \"posterior_views\": bl_rets.copy() if isinstance(bl_rets, np.ndarray) else bl_rets,\n",
    "                })\n",
    "                w_dict = {a: 1.0 / n_assets for a in assets}\n",
    "            w_array = np.array([w_dict[a] for a in assets])\n",
    "        else:\n",
    "            w_array = w_prev.copy()\n",
    "\n",
    "        # Trading cost\n",
    "        traded_fraction = np.sum(np.abs(w_array - w_prev))\n",
    "        cost = gross_growth * traded_fraction * transaction_cost\n",
    "\n",
    "        # New portfolio value\n",
    "        portfolio_vals[t] = gross_growth - cost\n",
    "        weight_history[t] = w_array\n",
    "        w_prev = w_array\n",
    "\n",
    "    return portfolio_vals, weight_history, fallback_records\n",
    "\n",
    "\n",
    "# --- 4. Backtesting & performance ---\n",
    "def backtest_portfolio(returns, weights, transaction_cost=0.0007):\n",
    "    \"\"\"\n",
    "    Simple hold & rebal once at t=0. Deduct cost on initial notional only.\n",
    "    \"\"\"\n",
    "    T = len(returns)\n",
    "    if T == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    portfolio_vals = np.zeros(T)\n",
    "    # Initial cost\n",
    "    cost_init = np.sum(np.abs(weights)) * transaction_cost\n",
    "    portfolio_vals[0] = 1.0 - cost_init\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        ret_t = returns.iloc[t].values\n",
    "        portfolio_vals[t + 1] = portfolio_vals[t] * (1.0 + np.dot(weights, ret_t))\n",
    "\n",
    "    return portfolio_vals\n",
    "\n",
    "def compute_performance_metrics(portfolio_vals, weight_history=None, annual_factor=250):\n",
    "    \"\"\"\n",
    "    Calculates standard portfolio metrics (Sharpe, Sortino, etc.).\n",
    "    \"\"\"\n",
    "    pv = np.asarray(portfolio_vals)\n",
    "    if len(pv) < 2:\n",
    "        # Not enough data points to compute real metrics\n",
    "        return {\n",
    "            \"Annualized Return\": np.nan,\n",
    "            \"Cumulative Return\": np.nan,\n",
    "            \"Volatility\": np.nan,\n",
    "            \"Downside Deviation\": np.nan,\n",
    "            \"Max Drawdown\": np.nan,\n",
    "            \"Sharpe Ratio\": np.nan,\n",
    "            \"Sortino Ratio\": np.nan,\n",
    "            \"Calmar Ratio\": np.nan,\n",
    "            \"Turnover Rate\": np.nan,\n",
    "        }\n",
    "\n",
    "    rets = np.diff(pv) / pv[:-1]\n",
    "    ann_ret = rets.mean() * annual_factor\n",
    "    cum_ret = pv[-1] / pv[0] - 1\n",
    "    ann_vol = rets.std() * np.sqrt(annual_factor)\n",
    "\n",
    "    negative_rets = rets[rets < 0]\n",
    "    ddev = (negative_rets.std() * np.sqrt(annual_factor)) if len(negative_rets) > 0 else 0.0\n",
    "\n",
    "    max_dd = (pv / np.maximum.accumulate(pv) - 1).min()\n",
    "    sharpe = ann_ret / (ann_vol + 1e-12)\n",
    "    sortino = ann_ret / ddev if ddev > 1e-12 else np.nan\n",
    "    calmar  = ann_ret / abs(max_dd) if max_dd < 0 else np.nan\n",
    "\n",
    "    # Average turnover\n",
    "    if weight_history is not None and len(weight_history) > 1:\n",
    "        turnovers = []\n",
    "        for t in range(1, len(weight_history)):\n",
    "            turnovers.append(np.sum(np.abs(weight_history[t] - weight_history[t-1])))\n",
    "        avg_turnover = np.mean(turnovers)\n",
    "    else:\n",
    "        avg_turnover = 0.0\n",
    "\n",
    "    return {\n",
    "        \"Annualized Return\": ann_ret,\n",
    "        \"Cumulative Return\": cum_ret,\n",
    "        \"Volatility\": ann_vol,\n",
    "        \"Downside Deviation\": ddev,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Sortino Ratio\": sortino,\n",
    "        \"Calmar Ratio\": calmar,\n",
    "        \"Turnover Rate\": avg_turnover,\n",
    "    }\n",
    "\n",
    "def equal_weight_allocation(n_assets):\n",
    "    \"\"\" Returns an equal-weight allocation vector. \"\"\"\n",
    "    return np.ones(n_assets) / n_assets\n",
    "\n",
    "\n",
    "# --- 5. Allocation simulation using only EW and SJM-BL ---\n",
    "def run_allocation_simulation(\n",
    "    df,\n",
    "    lam_sjm=50,\n",
    "    risk_free_rate=0.02/252,\n",
    "    transaction_cost=0.0007,\n",
    "    bl_tau=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits df 80/20, trains SJM, predicts states, then runs two strategies:\n",
    "    1) Equal-weight\n",
    "    2) SJM-BL\n",
    "    Returns performance dict and fallback events.\n",
    "    \"\"\"\n",
    "    # 1) Check the columns\n",
    "    missing_cols = [col for col in ASSETS if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"DataFrame is missing required columns: {missing_cols}\")\n",
    "\n",
    "    # 2) Split check\n",
    "    split_idx = int(len(df) * 0.8)\n",
    "    if split_idx < 1 or (len(df) - split_idx) < 1:\n",
    "        raise ValueError(\"Not enough data in df for an 80/20 train-test split.\")\n",
    "\n",
    "    df_train = df.iloc[:split_idx]\n",
    "    df_test  = df.iloc[split_idx:]\n",
    "    T_test = len(df_test)\n",
    "\n",
    "    # Train SJM for each asset\n",
    "    sjm_models = []\n",
    "    sjm_clippers = []\n",
    "    sjm_scalers = []\n",
    "    sjm_states_train = np.zeros((split_idx, N_ASSETS), dtype=int)\n",
    "    for i, asset in enumerate(ASSETS):\n",
    "        series_train = df_train[asset]\n",
    "        sjm_mod, sjm_clip, sjm_scale = train_sjm_single_asset(\n",
    "            series_train,\n",
    "            n_components=2,\n",
    "            max_feats=4,\n",
    "            lam=lam_sjm\n",
    "        )\n",
    "        feats_train = compute_sjm_features(series_train)\n",
    "        feats_train = feats_train.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "        X_train_clip = sjm_clip.transform(feats_train)\n",
    "        X_train_scl  = sjm_scale.transform(X_train_clip)\n",
    "        st_sjm = sjm_mod.predict(X_train_scl)\n",
    "\n",
    "        sjm_models.append(sjm_mod)\n",
    "        sjm_clippers.append(sjm_clip)\n",
    "        sjm_scalers.append(sjm_scale)\n",
    "        sjm_states_train[:, i] = st_sjm\n",
    "\n",
    "    # Compute regime means from training data\n",
    "    sjm_regime_means = []\n",
    "    for i in range(N_ASSETS):\n",
    "        asset_train = df_train.iloc[:, i]\n",
    "        m_sjm, _ = get_regime_means_stds_single_asset(asset_train, sjm_states_train[:, i])\n",
    "        sjm_regime_means.append(m_sjm)\n",
    "\n",
    "    # Predict SJM states for the test period (using an expanding window approach)\n",
    "    sjm_states_test = np.zeros((T_test, N_ASSETS), dtype=int)\n",
    "    full_series = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)\n",
    "    for i, asset in enumerate(ASSETS):\n",
    "        asset_full = full_series[asset]\n",
    "        feats_full = compute_sjm_features(asset_full)\n",
    "        feats_full = feats_full.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "        X_full_clip = sjm_clippers[i].transform(feats_full)\n",
    "        X_full_scl  = sjm_scalers[i].transform(X_full_clip)\n",
    "\n",
    "        for t in range(T_test):\n",
    "            end_idx = split_idx + t + 1  # end index in the full data\n",
    "            partial_X = X_full_scl[:end_idx]\n",
    "            partial_states = sjm_models[i].predict(partial_X)\n",
    "            # Use the last predicted state for time t without negative indexing\n",
    "            last_index = len(partial_states) - 1\n",
    "            sjm_states_test[t, i] = partial_states[last_index]\n",
    "\n",
    "    # 1) Equal Weight strategy\n",
    "    w_ew = equal_weight_allocation(N_ASSETS)\n",
    "    pv_ew = backtest_portfolio(df_test, w_ew, transaction_cost=transaction_cost)\n",
    "    w_hist_ew = np.tile(w_ew, (T_test, 1))\n",
    "\n",
    "    # 2) SJM-BL strategy\n",
    "    pv_sjmbl, w_sjmbl, fallback_sjmbl = regime_based_bl_backtest_flatprior(\n",
    "        df_train,\n",
    "        df_test,\n",
    "        sjm_states_test,\n",
    "        sjm_states_train[split_idx - 1, :],  # use the last training row explicitly\n",
    "        sjm_regime_means,\n",
    "        transaction_cost=transaction_cost,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        bl_tau=bl_tau,\n",
    "        halflife=126\n",
    "    )\n",
    "\n",
    "    perf = {\n",
    "        \"EW\": compute_performance_metrics(pv_ew, w_hist_ew),\n",
    "        \"SJM-BL\": compute_performance_metrics(pv_sjmbl, w_sjmbl)\n",
    "    }\n",
    "    fallback_events = {\"SJM-BL\": fallback_sjmbl}\n",
    "    return perf, fallback_events\n",
    "\n",
    "\n",
    "\n",
    "# --- 6. Monte Carlo simulation for a given lambda ---\n",
    "def single_simulation_run(run_id, T_sim=1000, lam_sjm=50, risk_free_rate=0.02/252,\n",
    "                          transaction_cost=0.0007, bl_tau=0.05):\n",
    "    \"\"\"\n",
    "    Creates a 2-state dataset, runs the two strategies (EW & SJM-BL),\n",
    "    returns the performance results.\n",
    "    \"\"\"\n",
    "    seed = run_id * 1000 + 100  # reproducibility\n",
    "    df_sim, _ = simulate_2state_data(T_sim, seed=seed)\n",
    "    return run_allocation_simulation(df_sim, lam_sjm, risk_free_rate, transaction_cost, bl_tau)\n",
    "\n",
    "def run_monte_carlo_for_lambda(n_runs=8, T_sim=1000, lam_sjm=50, risk_free_rate=0.02/252,\n",
    "                               transaction_cost=0.0007, bl_tau=0.05):\n",
    "    \"\"\"\n",
    "    Runs multiple simulations in parallel for a given lambda,\n",
    "    aggregates results.\n",
    "    \"\"\"\n",
    "    # Use up to 6 cores\n",
    "    results = Parallel(n_jobs=6)(\n",
    "        delayed(single_simulation_run)(\n",
    "            i+1, T_sim, lam_sjm, risk_free_rate, transaction_cost, bl_tau\n",
    "        )\n",
    "        for i in range(n_runs)\n",
    "    )\n",
    "\n",
    "    strategies = [\"EW\", \"SJM-BL\"]\n",
    "    metric_keys = [\n",
    "        \"Annualized Return\", \"Cumulative Return\", \"Volatility\",\n",
    "        \"Downside Deviation\", \"Max Drawdown\", \"Sharpe Ratio\",\n",
    "        \"Sortino Ratio\", \"Calmar Ratio\", \"Turnover Rate\"\n",
    "    ]\n",
    "    all_metrics = {\n",
    "        st: {m: [] for m in metric_keys} for st in strategies\n",
    "    }\n",
    "\n",
    "    # Collect performance metrics\n",
    "    for perf, _ in results:\n",
    "        for st in strategies:\n",
    "            for mkey in metric_keys:\n",
    "                all_metrics[st][mkey].append(perf[st][mkey])\n",
    "\n",
    "    return all_metrics, results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lambda_grid = [10, 25, 50, 75, 100, 125]  # Grid of lambda values\n",
    "    T_sim = 5000\n",
    "    n_simulations = 8\n",
    "\n",
    "    summary_results = {}\n",
    "    for lam in lambda_grid:\n",
    "        print(f\"\\nRunning simulations for lambda = {lam}...\")\n",
    "        metrics, _ = run_monte_carlo_for_lambda(\n",
    "            n_runs=n_simulations,\n",
    "            T_sim=T_sim,\n",
    "            lam_sjm=lam\n",
    "        )\n",
    "        summary_results[lam] = metrics\n",
    "\n",
    "        # Print summary stats\n",
    "        for strategy, mdict in metrics.items():\n",
    "            print(f\"\\nStrategy: {strategy} (lambda = {lam})\")\n",
    "            for mkey, values in mdict.items():\n",
    "                mean_val = np.nanmean(values)\n",
    "                std_val  = np.nanstd(values)\n",
    "                print(f\"{mkey}: Mean = {mean_val:.4f}, Std = {std_val:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
