{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SJM-BL Simulation study (scenario 1)\n",
    "### 1.0 Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For HMM and model training\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.stats import wilcoxon\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Import jumpmodels (including our custom preprocess functions)\n",
    "from jumpmodels.sparse_jump import SparseJumpModel\n",
    "from jumpmodels.preprocess import StandardScalerPD, DataClipperStd\n",
    "import scipy.stats as stats\n",
    "from jumpmodels.plot import plot_regimes_and_cumret, savefig_plt\n",
    "\n",
    "\n",
    "# Importing Portfolio Packages\n",
    "from pypfopt.black_litterman import BlackLittermanModel, market_implied_risk_aversion\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import base_optimizer, expected_returns, risk_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Data Simulation\n",
    "\n",
    "#### 2.1 Simulating the 1-state data\n",
    "We are simulating 6 fictional assets which are representing the 6 factors in our framework\n",
    "- **1-State:** A single regime with Student‑t returns.\n",
    "- **2-State:** A two-regime (bull/bear) HMM with state-dependent parameters.\n",
    "- **3-State:** A three-regime HMM with specified means and volatilitie\n",
    "\n",
    "All assets have the same expected return and volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define asset names and seed RNG for reproducibility.\n",
    "assets = [\"Value\", \"Growth\", \"LowVol\", \"Size\", \"Momentum\", \"Quality\"]\n",
    "n_assets = len(assets)\n",
    "rng = np.random.default_rng(42)  # random seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_1state_data(T):\n",
    "    \"\"\"\n",
    "    1-state model: returns follow a Student-t distribution.\n",
    "    \"\"\"\n",
    "    mu = 0.000461\n",
    "    sig = 0.008388\n",
    "    dof = 5\n",
    "    # Create a correlation matrix with off-diagonals = 0.185\n",
    "    corr = np.full((n_assets, n_assets), 0.185)\n",
    "    np.fill_diagonal(corr, 1.0)  # set diagonals to 1\n",
    "    Cov = (sig * np.ones(n_assets))[:, None] @ (sig * np.ones(n_assets))[None, :] * corr\n",
    "\n",
    "    # Generate multivariate draws and scale using chi-square factor\n",
    "    z = rng.multivariate_normal(mean=np.zeros(n_assets), cov=Cov, size=T)\n",
    "    chi = rng.chisquare(dof, size=T)\n",
    "    factor = np.sqrt(dof / chi)\n",
    "    rets = mu + z * factor[:, np.newaxis]\n",
    "\n",
    "    return pd.DataFrame(rets, columns=assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Simulating 2-state data\n",
    "\n",
    "This function simulates a 2-state HMM (bull/bear) with state‐dependent Student‑t returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_2state_data(T):\n",
    "    \"\"\"\n",
    "    2-state HMM: bull and bear regimes.\n",
    "    \"\"\"\n",
    "    transmat = np.array([[0.9976, 0.0024],\n",
    "                         [0.0232, 0.9768]])\n",
    "    states = np.zeros(T, dtype=int)\n",
    "    states[0] = rng.integers(2)  # random starting state\n",
    "    for t in range(1, T):\n",
    "        states[t] = rng.choice(2, p=transmat[states[t - 1]])\n",
    "\n",
    "    mu_dict = {0: 0.0006, 1: -0.000881}\n",
    "    sig_dict = {0: 0.00757, 1: 0.0163}\n",
    "    corr = np.full((n_assets, n_assets), 0.185)\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "\n",
    "    rets = np.zeros((T, n_assets))\n",
    "    dof = 5\n",
    "    for t in range(T):\n",
    "        s = states[t]\n",
    "        mu_s = np.full(n_assets, mu_dict[s])\n",
    "        sig_s = np.full(n_assets, sig_dict[s])\n",
    "        Cov_s = np.outer(sig_s, sig_s) * corr\n",
    "        z = rng.multivariate_normal(mean=np.zeros(n_assets), cov=Cov_s)\n",
    "        chi = rng.chisquare(dof)\n",
    "        factor = np.sqrt(dof / chi)\n",
    "        rets[t] = mu_s + factor * z\n",
    "\n",
    "    return pd.DataFrame(rets, columns=assets), states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Simulating 3-state data\n",
    "\n",
    "We are simulating 6 fictional assets which are representing the 6 factors in our framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_3state_data(T):\n",
    "    \"\"\"\n",
    "    3-state HMM: three regimes with specified means and volatilities.\n",
    "    \"\"\"\n",
    "    transmat = np.array([[0.9950, 0.004335, 0.000665],\n",
    "                         [0.01667, 0.95, 0.03333],\n",
    "                         [0.00652, 0.04348, 0.9500]])\n",
    "    states = np.zeros(T, dtype=int)\n",
    "    states[0] = rng.integers(3)\n",
    "    for t in range(1, T):\n",
    "        states[t] = rng.choice(3, p=transmat[states[t - 1]])\n",
    "\n",
    "    mu_list = [0.0005862, 0.0, -0.0008672]\n",
    "    sig_list = [0.0075313, 0.0135351, 0.0163387]\n",
    "    corr = np.full((n_assets, n_assets), 0.185)\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "\n",
    "    rets = np.zeros((T, n_assets))\n",
    "    dof = 5\n",
    "    for t in range(T):\n",
    "        s = states[t]\n",
    "        mu_s = np.full(n_assets, mu_list[s])\n",
    "        sig_s = np.full(n_assets, sig_list[s])\n",
    "        Cov_s = np.outer(sig_s, sig_s) * corr\n",
    "        z = rng.multivariate_normal(mean=np.zeros(n_assets), cov=Cov_s)\n",
    "        chi = rng.chisquare(dof)\n",
    "        factor = np.sqrt(dof / chi)\n",
    "        rets[t] = mu_s + factor * z\n",
    "\n",
    "    return pd.DataFrame(rets, columns=assets), states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Training Regime Models\n",
    "\n",
    "#### 3.1 Training HMM using kmeans clustering initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hmm_kmeans(X, n_components=2, random_state=42):\n",
    "    \"\"\"\n",
    "    Fit a GaussianHMM using k-means for initialization.\n",
    "    \"\"\"\n",
    "    model = GaussianHMM(n_components=n_components, covariance_type=\"diag\",\n",
    "                        n_iter=100, random_state=random_state)\n",
    "    kmeans = KMeans(n_clusters=n_components, n_init=10, random_state=random_state)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    means, covars = [], []\n",
    "    for i in range(n_components):\n",
    "        obs_i = X[labels == i]\n",
    "        means.append(obs_i.mean(axis=0))\n",
    "        covars.append(obs_i.var(axis=0) + 1e-2)\n",
    "    # Set HMM parameters\n",
    "    model.startprob_ = np.ones(n_components) / n_components\n",
    "    model.transmat_ = np.ones((n_components, n_components)) / n_components\n",
    "    model.means_ = np.array(means)\n",
    "    model.covars_ = np.array(covars)\n",
    "    model.init_params = 'tmc'\n",
    "\n",
    "    model.fit(X)\n",
    "    pred_states = model.predict(X)\n",
    "    return model, pred_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Training Sparse Jump model with max_feats=9 and lambda=80\n",
    "##### 3.2.1 Defining feature selection framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(X):\n",
    "    X_df = pd.DataFrame(X)\n",
    "    clipper = DataClipperStd(mul=3.0)  # clip outliers\n",
    "    scaler = StandardScalerPD()        # standardize data\n",
    "    X_clipped = clipper.fit_transform(X_df)\n",
    "    X_scaled = scaler.fit_transform(X_clipped)\n",
    "    return X_scaled.values\n",
    "\n",
    "\n",
    "def compute_temporal_features(y, l):\n",
    "    \"\"\"\n",
    "    Compute 9 temporal features using a window of length l.\n",
    "    \"\"\"\n",
    "    T = len(y)\n",
    "    feats = np.zeros((T, 9), dtype=float)\n",
    "    half = (l - 1) // 2\n",
    "    for t in range(T):\n",
    "        feats[t, 0] = y[t]\n",
    "        feats[t, 1] = abs(y[t] - y[t-1]) if t > 0 else 0.\n",
    "        feats[t, 2] = abs(y[t+1] - y[t]) if t < (T-1) else 0.\n",
    "        left_c = max(0, t - half)\n",
    "        right_c = min(T, t + half + 1)\n",
    "        window_c = y[left_c:right_c]\n",
    "        feats[t, 3] = np.mean(window_c)\n",
    "        feats[t, 4] = np.std(window_c)\n",
    "        left_l = max(0, t - l)\n",
    "        right_l = t\n",
    "        window_l = y[left_l:right_l]\n",
    "        feats[t, 5] = np.mean(window_l) if len(window_l) > 0 else 0.\n",
    "        feats[t, 6] = np.std(window_l) if len(window_l) > 0 else 0.\n",
    "        left_r = t\n",
    "        right_r = min(T, t + l)\n",
    "        window_r = y[left_r:right_r]\n",
    "        feats[t, 7] = np.mean(window_r) if len(window_r) > 0 else 0.\n",
    "        feats[t, 8] = np.std(window_r) if len(window_r) > 0 else 0.\n",
    "    return feats\n",
    "\n",
    "\n",
    "def combine_features(y, l_list=[5, 13]):\n",
    "    feat_list = []\n",
    "    for l in l_list:\n",
    "        feat_list.append(compute_temporal_features(y, l))\n",
    "    return np.hstack(feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sjm(X, max_feats=9.0, lam=80.0, n_components=2, random_state=42):\n",
    "    sjm = SparseJumpModel(n_components=n_components,\n",
    "                          max_feats=max_feats,\n",
    "                          jump_penalty=lam,\n",
    "                          cont=False,\n",
    "                          max_iter=20,\n",
    "                          random_state=random_state)\n",
    "    sjm.fit(X)\n",
    "    return sjm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Allocation simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Allocation workhorse functions\n",
    "In this code we create the in which we fit the following models (each done in a seperate for loop such that we can store the relevant data such as return, weights, etc. in seperate dfs):\n",
    "1. Equal weigted\n",
    "2. Inverse volatility weighted\n",
    "3. Mean-Variance-Optimal static portfolio\n",
    "4. Hidden Markov Model Black Litterman where infered states are the identified regimes\n",
    "5. Sparse Jump Model Black Litterman where infered states are the identified regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_FREE_RATE = 0.02 / 252  # ~0.000079 per day, for example\n",
    "TRANSACTION_COST = 0.0005\n",
    "BL_TAU = 0.05\n",
    "\n",
    "def static_mvo_allocation(returns):\n",
    "    mu = expected_returns.mean_historical_return(returns, returns_data=True)\n",
    "    S = risk_models.sample_cov(returns)\n",
    "    S_reg = S + 1e-6 * np.eye(S.shape[0])\n",
    "    # Use SCS instead of ECOS\n",
    "    ef = EfficientFrontier(mu, S_reg, weight_bounds=(0, 1), solver=\"SCS\")\n",
    "    weights = ef.max_sharpe(risk_free_rate=RISK_FREE_RATE)\n",
    "    return ef.clean_weights()\n",
    "\n",
    "\n",
    "def inverse_vol_weights(returns):\n",
    "    \"\"\"\n",
    "    Compute weights based on inverse volatility.\n",
    "    \"\"\"\n",
    "    stds = returns.std(axis=0).values\n",
    "    inv = 1.0 / (stds + 1e-12)  # avoid division by zero\n",
    "    return inv / inv.sum()\n",
    "\n",
    "\n",
    "def backtest_portfolio(returns, weights):\n",
    "    \"\"\"\n",
    "    Backtest a portfolio with fixed weights.\n",
    "    \"\"\"\n",
    "    T = len(returns)\n",
    "    pv = np.zeros(T)\n",
    "    pv[0] = 1.0\n",
    "    for t in range(T - 1):\n",
    "        r = returns.iloc[t].values\n",
    "        pv[t + 1] = pv[t] * (1.0 + np.dot(weights, r))\n",
    "    return pv\n",
    "\n",
    "\n",
    "def bl_allocation(view_vector, prior_cov):\n",
    "    \"\"\"\n",
    "    Compute BL allocation given a view vector.\n",
    "    prior_cov must be a DataFrame with columns=assets for correct naming.\n",
    "    Uses a globally defined BL_TAU and does not explicitly incorporate RISK_FREE_RATE\n",
    "    because Black-Litterman typically modifies expected returns, not the Sharpe formula.\n",
    "    \"\"\"\n",
    "    viewdict = {asset: view for asset, view in zip(assets, view_vector)}\n",
    "    bl = BlackLittermanModel(\n",
    "        cov_matrix=prior_cov,\n",
    "        absolute_views=viewdict,\n",
    "        tau=BL_TAU,\n",
    "        risk_aversion=1\n",
    "    )\n",
    "    weights = bl.bl_weights()\n",
    "    return np.array([weights[asset] for asset in assets])\n",
    "\n",
    "\n",
    "def regime_based_bl_backtest(returns, states, regime_mu_dict, prior_cov):\n",
    "    \"\"\"\n",
    "    Perform dynamic BL allocation using regime signals.\n",
    "    Uses global RISK_FREE_RATE (if needed for the solver) and TRANSACTION_COST for trades.\n",
    "    \"\"\"\n",
    "    T = len(returns)\n",
    "    n = returns.shape[1]\n",
    "    pv = np.zeros(T)\n",
    "    pv[0] = 1.0\n",
    "    w_hist = np.zeros((T, n))\n",
    "    w_hist[0] = np.ones(n) / n\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        r = returns.iloc[t].values\n",
    "        pv[t + 1] = pv[t] * (1.0 + np.dot(w_hist[t], r))\n",
    "\n",
    "        # If regime changed, recalc new weights\n",
    "        if t == 0 or (states[t] != states[t - 1]):\n",
    "            Q = regime_mu_dict[states[t]]\n",
    "            w_new = bl_allocation(Q, prior_cov)\n",
    "        else:\n",
    "            w_new = w_hist[t]\n",
    "\n",
    "        w_hist[t + 1] = w_new\n",
    "\n",
    "        # Transaction cost\n",
    "        if t > 0:\n",
    "            turnover = np.sum(np.abs(w_hist[t + 1] - w_hist[t]))\n",
    "            cost = TRANSACTION_COST * turnover\n",
    "        else:\n",
    "            cost = 0.0\n",
    "        pv[t + 1] *= (1.0 - cost)\n",
    "\n",
    "    # Final day\n",
    "    r_last = returns.iloc[-1].values\n",
    "    pv[-1] = pv[-2] * (1.0 + np.dot(w_hist[-2], r_last))\n",
    "    return pv, w_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Performance metric evaluation:\n",
    "Here we divide the performance metric into. We assume 250 data points to be 1 year off trading:\n",
    "1. Return-Based Metrics \n",
    "\n",
    "Annualized Return: Average return per year. \n",
    "\n",
    "Cumulative Return: Total portfolio growth over time. \n",
    "\n",
    "2. Risk-Based Metrics \n",
    "\n",
    "Volatility: Standard deviation of returns. \n",
    "\n",
    "Downside Deviation: Measures negative return fluctuations. \n",
    "\n",
    "Max Drawdown (MDD): Largest portfolio decline from peak to trough. \n",
    "\n",
    "3. Risk-Adjusted Metrics \n",
    "\n",
    "Sharpe Ratio: Return per unit of total risk. \n",
    "\n",
    "Sortino Ratio: Return per unit of downside risk. \n",
    "\n",
    "Calmar Ratio: Return relative to max drawdown. \n",
    "\n",
    "4. Portfolio Stability & Adaptation \n",
    "\n",
    "Turnover Rate: Measures frequency of asset reallocation. \n",
    "\n",
    "\n",
    "We further split the performance three seperate tables with 1-state process, 2-state process, 3-state process\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(pv, annual_factor=250):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics for a given portfolio value series.\n",
    "    \"\"\"\n",
    "    pv = np.array(pv)\n",
    "    rets = np.diff(pv) / pv[:-1]\n",
    "    ann_ret = rets.mean() * annual_factor\n",
    "    cum_ret = pv[-1] / pv[0] - 1\n",
    "    ann_vol = rets.std() * np.sqrt(annual_factor)\n",
    "    sharpe = ann_ret / (ann_vol + 1e-12)\n",
    "    running_max = np.maximum.accumulate(pv)\n",
    "    drawdown = (pv - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    return {\n",
    "        \"AnnRet\": ann_ret,\n",
    "        \"CumRet\": cum_ret,\n",
    "        \"AnnVol\": ann_vol,\n",
    "        \"Sharpe\": sharpe,\n",
    "        \"MaxDD\": max_dd,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allocation(df, states=None, scenario_name=\"\"):\n",
    "    \"\"\"\n",
    "    Train HMM, SJM, then run 5 strategies (EW, IV, MVO, HMM-BL, SJM-BL).\n",
    "    \"\"\"\n",
    "    # Split 80/20\n",
    "    split_idx = int(len(df) * 0.8)\n",
    "    df_train = df.iloc[:split_idx]\n",
    "    df_test = df.iloc[split_idx:]\n",
    "\n",
    "    # Preprocess\n",
    "    clipper = DataClipperStd(mul=3.0)\n",
    "    scaler = StandardScalerPD()\n",
    "    df_train_clipped = clipper.fit_transform(df_train)\n",
    "    df_train_scaled = scaler.fit_transform(df_train_clipped)\n",
    "    X_train = df_train_scaled.values\n",
    "\n",
    "    df_test_clipped = clipper.transform(df_test)\n",
    "    df_test_scaled = scaler.transform(df_test_clipped)\n",
    "    X_test = df_test_scaled.values\n",
    "\n",
    "    # Train models\n",
    "    hmm_model, hmm_states_train = train_hmm_kmeans(X_train, n_components=2, random_state=42)\n",
    "    sjm_model = train_sjm(X_train, max_feats=9.0, lam=80.0, n_components=2, random_state=42)\n",
    "\n",
    "    # Helper to compute regime means from the original (unscaled) df\n",
    "    def get_regime_means(df_orig, labels):\n",
    "        regs = {}\n",
    "        for lab in np.unique(labels):\n",
    "            idx = np.where(labels == lab)[0]\n",
    "            regs[lab] = df_orig.iloc[idx].mean(axis=0).values\n",
    "        return regs\n",
    "\n",
    "    hmm_mu = get_regime_means(df_train, hmm_states_train)\n",
    "    sjm_mu = get_regime_means(df_train, sjm_model.predict(X_train))\n",
    "\n",
    "    # Keep prior_cov as a DataFrame for BL\n",
    "    prior_cov = df_train.cov()\n",
    "\n",
    "    # 1) Equal Weight\n",
    "    w_ew = np.ones(n_assets) / n_assets\n",
    "    pv_ew = backtest_portfolio(df_test, w_ew)\n",
    "\n",
    "    # 2) Inverse Vol\n",
    "    w_iv = inverse_vol_weights(df_test)\n",
    "    pv_iv = backtest_portfolio(df_test, w_iv)\n",
    "\n",
    "    # 3) Static MVO\n",
    "    w_mvo = static_mvo_allocation(df_test)\n",
    "    w_mvo_arr = np.array([w_mvo[asset] for asset in assets])\n",
    "    pv_mvo = backtest_portfolio(df_test, w_mvo_arr)\n",
    "\n",
    "    # 4) HMM-BL\n",
    "    hmm_test_states = hmm_model.predict(X_test)\n",
    "    pv_hmmbl, _ = regime_based_bl_backtest(\n",
    "        df_test, hmm_test_states, hmm_mu, prior_cov\n",
    "    )\n",
    "\n",
    "    # 5) SJM-BL\n",
    "    sjm_test_states = sjm_model.predict(X_test)\n",
    "    pv_sjmbl, _ = regime_based_bl_backtest(\n",
    "        df_test, sjm_test_states, sjm_mu, prior_cov\n",
    "    )\n",
    "\n",
    "    # Collect performance\n",
    "    perf = {\n",
    "        \"EW\": performance_metrics(pv_ew),\n",
    "        \"IV\": performance_metrics(pv_iv),\n",
    "        \"MVO\": performance_metrics(pv_mvo),\n",
    "        \"HMM-BL\": performance_metrics(pv_hmmbl),\n",
    "        \"SJM-BL\": performance_metrics(pv_sjmbl),\n",
    "    }\n",
    "    return perf\n",
    "\n",
    "# %%\n",
    "def run_scenario_1study(T_sim=5000):\n",
    "    results = {}\n",
    "    df1 = simulate_1state_data(T_sim)\n",
    "    df2, states2 = simulate_2state_data(T_sim)\n",
    "    df3, states3 = simulate_3state_data(T_sim)\n",
    "\n",
    "    results[\"1state\"] = run_allocation(df1, scenario_name=\"1state\")\n",
    "    results[\"2state\"] = run_allocation(df2, states2, scenario_name=\"2state\")\n",
    "    results[\"3state\"] = run_allocation(df3, states3, scenario_name=\"3state\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario_1study(T_sim=5000):\n",
    "    results = {}\n",
    "    df1 = simulate_1state_data(T_sim)\n",
    "    df2, states2 = simulate_2state_data(T_sim)\n",
    "    df3, states3 = simulate_3state_data(T_sim)\n",
    "\n",
    "    results[\"1state\"] = run_allocation(df1, scenario_name=\"1state\")\n",
    "    results[\"2state\"] = run_allocation(df2, states2, scenario_name=\"2state\")\n",
    "    results[\"3state\"] = run_allocation(df3, states3, scenario_name=\"3state\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 Main execution: Run simulation and output performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "Even though the 'means_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'm'\n",
      "Even though the 'covars_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'c'\n",
      "C:\\Users\\vri\\AppData\\Roaming\\Python\\Python312\\site-packages\\pypfopt\\black_litterman.py:258: UserWarning: Running Black-Litterman with no prior.\n",
      "  warnings.warn(\"Running Black-Litterman with no prior.\")\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "Even though the 'means_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'm'\n",
      "Even though the 'covars_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'c'\n",
      "C:\\Users\\vri\\AppData\\Roaming\\Python\\Python312\\site-packages\\pypfopt\\black_litterman.py:258: UserWarning: Running Black-Litterman with no prior.\n",
      "  warnings.warn(\"Running Black-Litterman with no prior.\")\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
      "Even though the 'means_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'm'\n",
      "Even though the 'covars_' attribute is set, it will be overwritten during initialization because 'init_params' contains 'c'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1STATE Performance Metrics ===\n",
      "          AnnRet    CumRet    AnnVol    Sharpe     MaxDD\n",
      "EW      0.087017  0.385971  0.103188  0.843288 -0.200317\n",
      "IV      0.088435  0.393969  0.102972  0.858819 -0.200164\n",
      "MVO     0.102794  0.454119  0.134714  0.763052 -0.221067\n",
      "HMM-BL  0.062525  0.254556  0.107495  0.581654 -0.232272\n",
      "SJM-BL  0.103717  0.477830  0.109186  0.949915 -0.219400\n",
      "=== 2STATE Performance Metrics ===\n",
      "          AnnRet    CumRet    AnnVol    Sharpe     MaxDD\n",
      "EW      0.128063  0.632178  0.104136  1.229762 -0.128391\n",
      "IV      0.126361  0.621344  0.103809  1.217244 -0.127567\n",
      "MVO     0.167727  0.884404  0.134969  1.242714 -0.119995\n",
      "HMM-BL  0.104461  0.084495  0.409762  0.254931 -0.461107\n",
      "SJM-BL  0.152016  0.781963  0.121614  1.249993 -0.126174\n",
      "=== 3STATE Performance Metrics ===\n",
      "          AnnRet    CumRet    AnnVol    Sharpe     MaxDD\n",
      "EW      0.182265  1.037899  0.089982  2.025558 -0.120730\n",
      "IV      0.182220  1.037655  0.089817  2.028790 -0.120223\n",
      "MVO     0.222828  1.365814  0.120377  1.851088 -0.139184\n",
      "HMM-BL  0.149257  0.774850  0.106304  1.404057 -0.137256\n",
      "SJM-BL  0.182784  1.039957  0.092916  1.967207 -0.125688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vri\\AppData\\Roaming\\Python\\Python312\\site-packages\\pypfopt\\black_litterman.py:258: UserWarning: Running Black-Litterman with no prior.\n",
      "  warnings.warn(\"Running Black-Litterman with no prior.\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sim_results = run_scenario_1study(T_sim=5000)\n",
    "    for key, res in sim_results.items():\n",
    "        print(f\"=== {key.upper()} Performance Metrics ===\")\n",
    "        print(pd.DataFrame(res).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.0 Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
