{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Study for Noise Filtering\n",
    "\n",
    "This is the v2 for the simulation study on the sparse jump model comparison with HMM, to show that SJM is able to filter away noisy data by using the weighting in the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jumpmodel-related\n",
    "from jumpmodels.sparse_jump import SparseJumpModel\n",
    "from jumpmodels.jump import JumpModel\n",
    "from jumpmodels.preprocess import StandardScalerPD, DataClipperStd\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Simulation & Utility Functions\n",
    "def simulate_data(T, P, mu, random_state=None): \"\"\" Simulate data from a 2-state Gaussian HMM with correlation (tbd) between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(T, P, mu, random_state=None):\n",
    "    \"\"\"\n",
    "    Simulate data from a 2-state Gaussian HMM with correlated noise for features beyond\n",
    "    the first 15 informative features.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Transition matrix for 2 states\n",
    "    transmat = np.array([[0.9976, 0.0024],\n",
    "                         [0.0232, 0.9768]])\n",
    "\n",
    "    # Compute stationary distribution\n",
    "    eigvals, eigvecs = np.linalg.eig(transmat.T)\n",
    "    stat = np.real(eigvecs[:, np.isclose(eigvals, 1)])\n",
    "    stat = stat[:, 0]\n",
    "    stat = stat / np.sum(stat)\n",
    "\n",
    "    # Generate state sequence\n",
    "    states = np.zeros(T, dtype=int)\n",
    "    states[0] = rng.choice(np.arange(2), p=stat)\n",
    "    for t in range(1, T):\n",
    "        states[t] = rng.choice(np.arange(2), p=transmat[states[t-1]])\n",
    "\n",
    "    # Define means for each state: first 15 features are informative\n",
    "    means = np.zeros((2, P))\n",
    "    if P >= 15:\n",
    "        means[0, :15] = mu\n",
    "        means[1, :15] = -mu\n",
    "    else:\n",
    "        means[0, :P] = mu\n",
    "        means[1, :P] = -mu\n",
    "\n",
    "    # Prepare correlated noise for features beyond the first 15\n",
    "    informative = 15\n",
    "    if P > informative:\n",
    "        num_noise = P - informative\n",
    "        sigma = np.full((num_noise, num_noise), 0.213)\n",
    "        np.fill_diagonal(sigma, 1.0)\n",
    "        C = np.linalg.cholesky(sigma)\n",
    "    else:\n",
    "        C = None\n",
    "\n",
    "    # Generate observations\n",
    "    X = np.zeros((T, P))\n",
    "    for t in range(T):\n",
    "        n_inf = min(P, informative)\n",
    "        X[t, :n_inf] = rng.normal(loc=means[states[t], :n_inf], scale=1.0, size=n_inf)\n",
    "        if P > informative:\n",
    "            noise_indep = rng.normal(loc=0.0, scale=1.0, size=P - informative)\n",
    "            X[t, informative:] = C @ noise_indep\n",
    "    return X, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Aligning Predicted Labels With True Labels using the Hungarian Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels(true_labels, pred_labels):\n",
    "    \"\"\"\n",
    "    Align predicted labels with true labels using the Hungarian algorithm.\n",
    "    \"\"\"\n",
    "    D = confusion_matrix(true_labels, pred_labels)\n",
    "    row_ind, col_ind = linear_sum_assignment(-D)\n",
    "    mapping = {col: row for row, col in zip(row_ind, col_ind)}\n",
    "    aligned = np.array([mapping[x] for x in pred_labels])\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up the function to calcuate the BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bac(true_states, pred_states):\n",
    "    \"\"\"\n",
    "    Compute balanced accuracy score after aligning predicted state labels.\n",
    "    \"\"\"\n",
    "    aligned_pred = align_labels(true_states, pred_states)\n",
    "    return balanced_accuracy_score(true_states, aligned_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Computing per state accuracy and calculating statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_state_accuracy(true_states, pred_states):\n",
    "    \"\"\"\n",
    "    Compute per-state accuracy and BAC.\n",
    "    \"\"\"\n",
    "    aligned = align_labels(true_states, pred_states)\n",
    "    cm = confusion_matrix(true_states, aligned, labels=[0, 1])\n",
    "    acc1 = cm[0, 0] / cm[0].sum() if cm[0].sum() > 0 else np.nan\n",
    "    acc2 = cm[1, 1] / cm[1].sum() if cm[1].sum() > 0 else np.nan\n",
    "    bac = (acc1 + acc2) / 2\n",
    "    return acc1, acc2, bac\n",
    "\n",
    "def compute_state_statistics(X, true_states, pred_states):\n",
    "    \"\"\"\n",
    "    Compute mean for each state.\n",
    "    \"\"\"\n",
    "    aligned = align_labels(true_states, pred_states)\n",
    "    stats_dict = {}\n",
    "    for state in [0, 1]:\n",
    "        idx = np.where(aligned == state)[0]\n",
    "        if len(idx) > 0:\n",
    "            stats_dict[f'state{state}_mean'] = np.mean(X[idx])\n",
    "        else:\n",
    "            stats_dict[f'state{state}_mean'] = np.nan\n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Computing transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition_probabilities(state_seq):\n",
    "    \"\"\"\n",
    "    Compute q12 and q21 from the state sequence.\n",
    "    q12: transitions from state 0 to 1 / total transitions from state 0.\n",
    "    q21: transitions from state 1 to 0 / total transitions from state 1.\n",
    "    \"\"\"\n",
    "    state_seq = np.array(state_seq)\n",
    "    prev = state_seq[:-1]\n",
    "    nxt = state_seq[1:]\n",
    "    if np.sum(prev == 0) > 0:\n",
    "        q12 = np.sum((prev == 0) & (nxt == 1)) / np.sum(prev == 0)\n",
    "    else:\n",
    "        q12 = np.nan\n",
    "    if np.sum(prev == 1) > 0:\n",
    "        q21 = np.sum((prev == 1) & (nxt == 0)) / np.sum(prev == 1)\n",
    "    else:\n",
    "        q21 = np.nan\n",
    "    return q12, q21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Standardizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize features using the same procedure as in study 2.\n",
    "    \"\"\"\n",
    "    X_df = pd.DataFrame(X)\n",
    "    clipper = DataClipperStd(mul=3.0)\n",
    "    scaler = StandardScalerPD()\n",
    "    X_clipped = clipper.fit_transform(X_df)\n",
    "    X_scaled = scaler.fit_transform(X_clipped)\n",
    "    return X_scaled.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Functions for model formulation\n",
    "\n",
    "### 4.1 HMM With Nystrup (2020b) initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mle(observations, n_components=2, init_type='default', seed=None):\n",
    "    \"\"\"\n",
    "    Fit a Gaussian HMM to the data with different init_type.\n",
    "    \"\"\"\n",
    "    model = GaussianHMM(n_components=n_components, covariance_type='diag', n_iter=100, random_state=seed)\n",
    "\n",
    "    if init_type == 'default':\n",
    "        model.startprob_ = np.array([1.0, 0.0])\n",
    "        model.transmat_ = np.array([[0.9, 0.1],\n",
    "                                    [0.1, 0.9]])\n",
    "        model.means_ = np.zeros((n_components, observations.shape[1]))\n",
    "        model.covars_ = np.full((n_components, observations.shape[1]), 1e-2)\n",
    "        model.init_params = ''\n",
    "    elif init_type == 'kmeans':\n",
    "        kmeans = KMeans(n_clusters=n_components, n_init=10, random_state=seed)\n",
    "        labels = kmeans.fit_predict(observations)\n",
    "        means = []\n",
    "        covars = []\n",
    "        for i in range(n_components):\n",
    "            obs_i = observations[labels == i]\n",
    "            means.append(np.mean(obs_i, axis=0))\n",
    "            covars.append(np.var(obs_i, axis=0) + 1e-2)\n",
    "        model.startprob_ = np.ones(n_components) / n_components\n",
    "        model.transmat_ = np.ones((n_components, n_components)) / n_components\n",
    "        model.means_ = np.array(means)\n",
    "        model.covars_ = np.array(covars)\n",
    "        model.init_params = 'tmc'\n",
    "\n",
    "    model.fit(observations)\n",
    "    pred_states = model.predict(observations)\n",
    "    return model, pred_states\n",
    "\n",
    "def run_mle_default(observations, seed=None):\n",
    "    return run_mle(observations, init_type='default', seed=seed)\n",
    "\n",
    "def run_mle_kmeans(observations, seed=None):\n",
    "    return run_mle(observations, init_type='kmeans', seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Normal (Standard) Jump Model with Grid Search over λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_jump_model_grid_search(X, true_states, n_components=2, random_state=None):\n",
    "    \"\"\"\n",
    "    Grid search for the jump model over a range of lambda values.\n",
    "    Uses set_params to avoid re-instantiating JumpModel each time.\n",
    "    \"\"\"\n",
    "    lambda_values = np.logspace(-2, 4, 14)\n",
    "    # Create one JumpModel instance (no jump_penalty at init)\n",
    "    model = JumpModel(n_components=n_components, jump_penalty=0.0, cont=False,\n",
    "                      max_iter=10, random_state=random_state)\n",
    "    best_bac = -np.inf\n",
    "    best_labels = None\n",
    "    best_lambda = None\n",
    "    grid_results = []\n",
    "\n",
    "    for lam in lambda_values:\n",
    "        # Update jump_penalty\n",
    "        model.set_params(jump_penalty=lam)\n",
    "        model.fit(X)\n",
    "        labels = model.labels_\n",
    "        bac = calculate_bac(true_states, labels)\n",
    "        grid_results.append({'lambda': lam, 'BAC': bac})\n",
    "\n",
    "        if bac > best_bac:\n",
    "            best_bac = bac\n",
    "            best_labels = labels\n",
    "            best_lambda = lam\n",
    "\n",
    "    return best_labels, best_bac, best_lambda, pd.DataFrame(grid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sparse Jump Model with Grid Search over λ and kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sparse_jump_model_grid_search(X, true_states, n_components=2, random_state=None):\n",
    "    \"\"\"\n",
    "    Grid search for the sparse jump model over combinations of lambda and kappa.\n",
    "    Uses set_params to avoid re-instantiating SparseJumpModel each time.\n",
    "    \"\"\"\n",
    "    lambdas = np.logspace(-1, 2, 7)\n",
    "    p = X.shape[1]\n",
    "    kappas = np.linspace(1, np.sqrt(p), 14)\n",
    "\n",
    "    # Create one SparseJumpModel instance\n",
    "    model = SparseJumpModel(n_components=n_components, jump_penalty=0.0, cont=False,\n",
    "                            max_iter=10, random_state=random_state)\n",
    "\n",
    "    best_bac = -np.inf\n",
    "    best_labels = None\n",
    "    best_lambda = None\n",
    "    best_kappa = None\n",
    "    grid_results = []\n",
    "\n",
    "    for lam in lambdas:\n",
    "        for kappa in kappas:\n",
    "            max_feats = kappa**2\n",
    "            # Update jump_penalty and max_feats\n",
    "            model.set_params(jump_penalty=lam, max_feats=max_feats)\n",
    "            model.fit(X)\n",
    "            labels = model.labels_\n",
    "            bac = calculate_bac(true_states, labels)\n",
    "\n",
    "            grid_results.append({'lambda': lam, 'kappa': kappa,\n",
    "                                 'max_feats': max_feats, 'BAC': bac})\n",
    "\n",
    "            if bac > best_bac:\n",
    "                best_bac = bac\n",
    "                best_labels = labels\n",
    "                best_lambda = lam\n",
    "                best_kappa = kappa\n",
    "\n",
    "    return best_labels, best_bac, best_lambda, best_kappa, pd.DataFrame(grid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Main Execution\n",
    " We split the code into three sections for each model and then combine results at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 16 CPU cores for parallel processing.\n",
      "Running simulations for mu=0.02 and P=15...\n",
      "Running simulations for mu=0.02 and P=30...\n",
      "Running simulations for mu=0.02 and P=60...\n",
      "Running simulations for mu=0.02 and P=150...\n",
      "Running simulations for mu=0.02 and P=300...\n",
      "Running simulations for mu=0.05 and P=15...\n",
      "Running simulations for mu=0.05 and P=30...\n",
      "Running simulations for mu=0.05 and P=60...\n",
      "Running simulations for mu=0.05 and P=150...\n",
      "Running simulations for mu=0.05 and P=300...\n",
      "Running simulations for mu=0.1 and P=15...\n",
      "Running simulations for mu=0.1 and P=30...\n",
      "Running simulations for mu=0.1 and P=60...\n",
      "Running simulations for mu=0.1 and P=150...\n",
      "Running simulations for mu=0.1 and P=300...\n",
      "Running simulations for mu=0.25 and P=15...\n",
      "Running simulations for mu=0.25 and P=30...\n",
      "Running simulations for mu=0.25 and P=60...\n",
      "Running simulations for mu=0.25 and P=150...\n",
      "Running simulations for mu=0.25 and P=300...\n",
      "Running simulations for mu=0.5 and P=15...\n",
      "Running simulations for mu=0.5 and P=30...\n",
      "Running simulations for mu=0.5 and P=60...\n",
      "Running simulations for mu=0.5 and P=150...\n",
      "Running simulations for mu=0.5 and P=300...\n",
      "Simulation results shape: (2500, 34)\n",
      "Jump grid search results shape: (35000, 5)\n",
      "Sparse Jump grid search results shape: (245000, 7)\n"
     ]
    }
   ],
   "source": [
    "T = 500\n",
    "mu_values = [0.02, 0.05, 0.1, 0.25, 0.5]\n",
    "p_values = [15, 30, 60, 150, 300]\n",
    "n_simulations = 100  # adjust as needed\n",
    "n_components = 2\n",
    "\n",
    "# Lists to collect simulation details and grid search results\n",
    "simulation_results = []\n",
    "grid_search_jump_list = []\n",
    "grid_search_sparse_list = []\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(f\"Detected {num_cores} CPU cores for parallel processing.\")\n",
    "\n",
    "for mu in mu_values:\n",
    "    for P in p_values:\n",
    "        print(f\"Running simulations for mu={mu} and P={P}...\")\n",
    "        # Parallelize simulations for this (mu, P)\n",
    "        def simulate_and_run(sim):\n",
    "            # Simulate once\n",
    "            X, true_states = simulate_data(T, P, mu, random_state=sim)\n",
    "\n",
    "            # MLE default and MLE_k\n",
    "            model_mle, pred_mle = run_mle_default(X, seed=sim)\n",
    "            model_mle_k, pred_mle_k = run_mle_kmeans(X, seed=sim)\n",
    "            bac_mle = calculate_bac(true_states, pred_mle)\n",
    "            bac_mle_k = calculate_bac(true_states, pred_mle_k)\n",
    "\n",
    "            # Standardize features for jump models\n",
    "            X_std = standardize_features(X)\n",
    "\n",
    "            # Jump model grid search\n",
    "            pred_jump, bac_jump, best_lambda_jump, df_grid_jump = run_jump_model_grid_search(\n",
    "                X_std, true_states, n_components=n_components, random_state=sim)\n",
    "\n",
    "            # Sparse jump model grid search\n",
    "            pred_sparse, bac_sparse, best_lambda_sparse, best_kappa_sparse, df_grid_sparse = run_sparse_jump_model_grid_search(\n",
    "                X_std, true_states, n_components=n_components, random_state=sim)\n",
    "\n",
    "            # Compute performance metrics\n",
    "            acc1_mle, acc2_mle, _ = compute_per_state_accuracy(true_states, pred_mle)\n",
    "            acc1_mle_k, acc2_mle_k, _ = compute_per_state_accuracy(true_states, pred_mle_k)\n",
    "            acc1_jump, acc2_jump, _ = compute_per_state_accuracy(true_states, pred_jump)\n",
    "            acc1_sparse, acc2_sparse, _ = compute_per_state_accuracy(true_states, pred_sparse)\n",
    "\n",
    "            stats_mle = compute_state_statistics(X, true_states, pred_mle)\n",
    "            stats_mle_k = compute_state_statistics(X, true_states, pred_mle_k)\n",
    "            stats_jump = compute_state_statistics(X, true_states, pred_jump)\n",
    "            stats_sparse = compute_state_statistics(X, true_states, pred_sparse)\n",
    "\n",
    "            q12_mle, q21_mle = compute_transition_probabilities(pred_mle)\n",
    "            q12_mle_k, q21_mle_k = compute_transition_probabilities(pred_mle_k)\n",
    "            q12_jump, q21_jump = compute_transition_probabilities(pred_jump)\n",
    "            q12_sparse, q21_sparse = compute_transition_probabilities(pred_sparse)\n",
    "\n",
    "            run_dict = {\n",
    "                'mu': mu,\n",
    "                'P': P,\n",
    "                'sim': sim,\n",
    "                # MLE (default)\n",
    "                'MLE_BAC': bac_mle,\n",
    "                'MLE_acc1': acc1_mle,\n",
    "                'MLE_acc2': acc2_mle,\n",
    "                'MLE_state0_mean': stats_mle.get('state0_mean', np.nan),\n",
    "                'MLE_state1_mean': stats_mle.get('state1_mean', np.nan),\n",
    "                'MLE_q12': q12_mle,\n",
    "                'MLE_q21': q21_mle,\n",
    "                # MLE_k (kmeans)\n",
    "                'MLEK_BAC': bac_mle_k,\n",
    "                'MLEK_acc1': acc1_mle_k,\n",
    "                'MLEK_acc2': acc2_mle_k,\n",
    "                'MLEK_state0_mean': stats_mle_k.get('state0_mean', np.nan),\n",
    "                'MLEK_state1_mean': stats_mle_k.get('state1_mean', np.nan),\n",
    "                'MLEK_q12': q12_mle_k,\n",
    "                'MLEK_q21': q21_mle_k,\n",
    "                # Jump Model\n",
    "                'Jump_BAC': bac_jump,\n",
    "                'Jump_acc1': acc1_jump,\n",
    "                'Jump_acc2': acc2_jump,\n",
    "                'Jump_state0_mean': stats_jump.get('state0_mean', np.nan),\n",
    "                'Jump_state1_mean': stats_jump.get('state1_mean', np.nan),\n",
    "                'Jump_q12': q12_jump,\n",
    "                'Jump_q21': q21_jump,\n",
    "                'Jump_best_lambda': best_lambda_jump,\n",
    "                # Sparse Jump Model\n",
    "                'SparseJump_BAC': bac_sparse,\n",
    "                'SparseJump_acc1': acc1_sparse,\n",
    "                'SparseJump_acc2': acc2_sparse,\n",
    "                'SparseJump_state0_mean': stats_sparse.get('state0_mean', np.nan),\n",
    "                'SparseJump_state1_mean': stats_sparse.get('state1_mean', np.nan),\n",
    "                'SparseJump_q12': q12_sparse,\n",
    "                'SparseJump_q21': q21_sparse,\n",
    "                'SparseJump_best_lambda': best_lambda_sparse,\n",
    "                'SparseJump_best_kappa': best_kappa_sparse\n",
    "            }\n",
    "\n",
    "            # Store grid search data frames with extra columns\n",
    "            df_grid_jump['mu'] = mu\n",
    "            df_grid_jump['P'] = P\n",
    "            df_grid_jump['sim'] = sim\n",
    "\n",
    "            df_grid_sparse['mu'] = mu\n",
    "            df_grid_sparse['P'] = P\n",
    "            df_grid_sparse['sim'] = sim\n",
    "\n",
    "            return run_dict, df_grid_jump, df_grid_sparse\n",
    "\n",
    "        results = Parallel(n_jobs=num_cores)(\n",
    "            delayed(simulate_and_run)(sim) for sim in range(n_simulations)\n",
    "        )\n",
    "\n",
    "        for run_dict, df_grid_jump, df_grid_sparse in results:\n",
    "            simulation_results.append(run_dict)\n",
    "            grid_search_jump_list.append(df_grid_jump)\n",
    "            grid_search_sparse_list.append(df_grid_sparse)\n",
    "\n",
    "# Final DataFrames\n",
    "df_simulation = pd.DataFrame(simulation_results)\n",
    "df_grid_jump = pd.concat(grid_search_jump_list, ignore_index=True)\n",
    "df_grid_sparse = pd.concat(grid_search_sparse_list, ignore_index=True)\n",
    "\n",
    "print(\"Simulation results shape:\", df_simulation.shape)\n",
    "print(\"Jump grid search results shape:\", df_grid_jump.shape)\n",
    "print(\"Sparse Jump grid search results shape:\", df_grid_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Wilcoxon Test Table Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon test results (Sparse Jump vs other models):\n",
      "      mu    P  p_value_SparseJump_vs_MLE  p_value_SparseJump_vs_MLEK  p_value_SparseJump_vs_Jump\n",
      "0   0.02   15               1.767995e-10                4.095127e-17                2.969775e-02\n",
      "1   0.02   30               3.895681e-18                3.895900e-18                8.390082e-04\n",
      "2   0.02   60               3.895900e-18                3.895681e-18                8.636290e-09\n",
      "3   0.02  150               3.895900e-18                3.895681e-18                1.392396e-10\n",
      "4   0.02  300               3.896120e-18                3.896120e-18                1.714458e-11\n",
      "5   0.05   15               2.345364e-10                5.129707e-17                2.162318e-02\n",
      "6   0.05   30               3.895681e-18                3.895900e-18                7.329036e-04\n",
      "7   0.05   60               3.895900e-18                3.895681e-18                5.626758e-09\n",
      "8   0.05  150               3.895900e-18                3.895681e-18                9.458167e-11\n",
      "9   0.05  300               3.896120e-18                3.896120e-18                4.200842e-11\n",
      "10  0.10   15               1.307236e-07                1.102051e-16                7.209137e-01\n",
      "11  0.10   30               3.895681e-18                4.015477e-18                5.609791e-03\n",
      "12  0.10   60               3.895900e-18                3.895681e-18                5.467336e-09\n",
      "13  0.10  150               3.895900e-18                3.895681e-18                7.611691e-10\n",
      "14  0.10  300               3.896120e-18                3.896120e-18                8.833245e-10\n",
      "15  0.25   15               3.139929e-07                6.681592e-13                9.394616e-03\n",
      "16  0.25   30               7.392902e-17                3.895241e-18                1.222224e-01\n",
      "17  0.25   60               5.696237e-18                3.895681e-18                1.229438e-05\n",
      "18  0.25  150               3.895900e-18                3.895681e-18                9.613656e-08\n",
      "19  0.25  300               3.896120e-18                3.896120e-18                6.359553e-10\n",
      "20  0.50   15               1.541100e-06                4.134916e-08                6.909448e-01\n",
      "21  0.50   30               3.408587e-12                2.824136e-16                3.719738e-01\n",
      "22  0.50   60               3.731198e-16                4.015250e-18                2.886802e-03\n",
      "23  0.50  150               5.696237e-18                3.895681e-18                4.193606e-10\n",
      "24  0.50  300               3.896120e-18                3.896120e-18                5.502068e-04\n"
     ]
    }
   ],
   "source": [
    "# Create a Wilcoxon table comparing Sparse Jump BAC versus the other models (MLE, MLEK, Jump)\n",
    "wilcoxon_rows = []\n",
    "\n",
    "for mu in mu_values:\n",
    "    for P in p_values:\n",
    "        df_subset = df_simulation[(df_simulation['mu'] == mu) & (df_simulation['P'] == P)]\n",
    "        if len(df_subset) < 2:\n",
    "            continue\n",
    "        # Compare BAC: Sparse Jump vs MLE\n",
    "        stat, p_sparse_mle = wilcoxon(df_subset['SparseJump_BAC'], df_subset['MLE_BAC'])\n",
    "        # Compare BAC: Sparse Jump vs MLE_k\n",
    "        stat, p_sparse_mlek = wilcoxon(df_subset['SparseJump_BAC'], df_subset['MLEK_BAC'])\n",
    "        # Compare BAC: Sparse Jump vs Jump\n",
    "        stat, p_sparse_jump = wilcoxon(df_subset['SparseJump_BAC'], df_subset['Jump_BAC'])\n",
    "\n",
    "        wilcoxon_rows.append({\n",
    "            'mu': mu,\n",
    "            'P': P,\n",
    "            'p_value_SparseJump_vs_MLE': p_sparse_mle,\n",
    "            'p_value_SparseJump_vs_MLEK': p_sparse_mlek,\n",
    "            'p_value_SparseJump_vs_Jump': p_sparse_jump\n",
    "        })\n",
    "\n",
    "df_wilcoxon = pd.DataFrame(wilcoxon_rows)\n",
    "print(\"Wilcoxon test results (Sparse Jump vs other models):\")\n",
    "print(df_wilcoxon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for mu=0.02 & P=15\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0180        0.0212        0.6797        0.3615        0.5512\n",
      "MLE k-means         0.0199        0.0032        0.6929        0.2977        0.5359\n",
      "Jump Model          0.0238        0.0010        0.7533        0.4845        0.6679\n",
      "Sparse Jump         0.0291       -0.0048        0.6794        0.6349        0.6919\n",
      "\n",
      "Summary for mu=0.02 & P=30\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0144        0.0060        0.5435        0.4920        0.5224\n",
      "MLE k-means         0.0094        0.0116        0.5447        0.4810        0.5187\n",
      "Jump Model          0.0151        0.0005        0.7518        0.4950        0.6714\n",
      "Sparse Jump         0.0222       -0.0149        0.7164        0.5931        0.6934\n",
      "\n",
      "Summary for mu=0.02 & P=60\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0155        0.0294        0.5368        0.4736        0.5108\n",
      "MLE k-means        -0.0275        0.0415        0.5374        0.4707        0.5102\n",
      "Jump Model         -0.0060        0.0175        0.7443        0.5042        0.6714\n",
      "Sparse Jump        -0.0195        0.0499        0.7109        0.6706        0.7220\n",
      "\n",
      "Summary for mu=0.02 & P=150\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0171        0.0215        0.5277        0.4828        0.5095\n",
      "MLE k-means        -0.0032        0.0079        0.5291        0.4857        0.5116\n",
      "Jump Model          0.0132       -0.0489        0.7557        0.4678        0.6623\n",
      "Sparse Jump         0.0189       -0.0344        0.7332        0.6217        0.7134\n",
      "\n",
      "Summary for mu=0.02 & P=300\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0627        0.0650        0.5284        0.5159        0.5233\n",
      "MLE k-means        -0.0277        0.0296        0.5327        0.5041        0.5208\n",
      "Jump Model         -0.0377        0.0890        0.7553        0.4624        0.6599\n",
      "Sparse Jump         0.0117        0.0026        0.7340        0.6359        0.7193\n",
      "\n",
      "Summary for mu=0.05 & P=15\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0468        0.0395        0.6893        0.3762        0.5620\n",
      "MLE k-means         0.0424        0.0298        0.7100        0.2783        0.5366\n",
      "Jump Model          0.0602       -0.0020        0.7391        0.5661        0.6938\n",
      "Sparse Jump         0.0611        0.0007        0.6937        0.6650        0.7112\n",
      "\n",
      "Summary for mu=0.05 & P=30\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0285        0.0160        0.5437        0.4837        0.5192\n",
      "MLE k-means         0.0223        0.0241        0.5448        0.4824        0.5193\n",
      "Jump Model          0.0276        0.0168        0.7595        0.4966        0.6759\n",
      "Sparse Jump         0.0396       -0.0105        0.7115        0.6074        0.6968\n",
      "\n",
      "Summary for mu=0.05 & P=60\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0093        0.0356        0.5368        0.4736        0.5108\n",
      "MLE k-means        -0.0154        0.0418        0.5378        0.4693        0.5098\n",
      "Jump Model          0.0050        0.0135        0.7439        0.5061        0.6719\n",
      "Sparse Jump        -0.0133        0.0512        0.7073        0.6715        0.7206\n",
      "\n",
      "Summary for mu=0.05 & P=150\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0146        0.0239        0.5277        0.4827        0.5095\n",
      "MLE k-means        -0.0010        0.0100        0.5286        0.4863        0.5116\n",
      "Jump Model          0.0142       -0.0397        0.7521        0.4751        0.6635\n",
      "Sparse Jump         0.0157       -0.0221        0.7365        0.6310        0.7188\n",
      "\n",
      "Summary for mu=0.05 & P=300\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0614        0.0663        0.5283        0.5159        0.5232\n",
      "MLE k-means        -0.0265        0.0308        0.5329        0.5048        0.5212\n",
      "Jump Model         -0.0408        0.0892        0.7562        0.4624        0.6604\n",
      "Sparse Jump         0.0059        0.0012        0.7342        0.6331        0.7183\n",
      "\n",
      "Summary for mu=0.1 & P=15\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0959        0.0594        0.7169        0.5087        0.6294\n",
      "MLE k-means         0.0887        0.0680        0.7113        0.3309        0.5585\n",
      "Jump Model          0.1099       -0.0227        0.8079        0.6662        0.7688\n",
      "Sparse Jump         0.1068       -0.0031        0.7659        0.6944        0.7592\n",
      "\n",
      "Summary for mu=0.1 & P=30\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0456        0.0400        0.5442        0.4828        0.5190\n",
      "MLE k-means         0.0432        0.0442        0.5450        0.4831        0.5197\n",
      "Jump Model          0.0606        0.0010        0.7794        0.5334        0.7007\n",
      "Sparse Jump         0.0615        0.0006        0.7426        0.6348        0.7234\n",
      "\n",
      "Summary for mu=0.1 & P=60\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0009        0.0458        0.5368        0.4726        0.5104\n",
      "MLE k-means        -0.0109        0.0580        0.5375        0.4732        0.5112\n",
      "Jump Model          0.0157        0.0067        0.7507        0.5137        0.6784\n",
      "Sparse Jump        -0.0014        0.0514        0.7265        0.6747        0.7315\n",
      "\n",
      "Summary for mu=0.1 & P=150\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0104        0.0280        0.5277        0.4827        0.5095\n",
      "MLE k-means        -0.0037        0.0211        0.5287        0.4854        0.5112\n",
      "Jump Model          0.0237       -0.0338        0.7522        0.4813        0.6660\n",
      "Sparse Jump         0.0101       -0.0022        0.7338        0.6319        0.7178\n",
      "\n",
      "Summary for mu=0.1 & P=300\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0594        0.0682        0.5284        0.5159        0.5233\n",
      "MLE k-means        -0.0243        0.0329        0.5328        0.5051        0.5213\n",
      "Jump Model         -0.0394        0.0893        0.7644        0.4650        0.6655\n",
      "Sparse Jump         0.0102       -0.0024        0.7321        0.6381        0.7193\n",
      "\n",
      "Summary for mu=0.25 & P=15\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.2525       -0.0266        0.8507        0.8550        0.8366\n",
      "MLE k-means         0.2417        0.0066        0.8332        0.6881        0.7641\n",
      "Jump Model          0.2535       -0.2166        0.9742        0.9296        0.9586\n",
      "Sparse Jump         0.2546       -0.1691        0.9389        0.9245        0.9389\n",
      "\n",
      "Summary for mu=0.25 & P=30\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.1160        0.0713        0.6177        0.5916        0.5999\n",
      "MLE k-means         0.1022        0.1089        0.5459        0.4810        0.5192\n",
      "Jump Model          0.1230       -0.0554        0.9212        0.8205        0.8879\n",
      "Sparse Jump         0.1291       -0.0670        0.9144        0.8699        0.9045\n",
      "\n",
      "Summary for mu=0.25 & P=60\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0300        0.0791        0.5406        0.4839        0.5169\n",
      "MLE k-means         0.0257        0.0826        0.5378        0.4754        0.5123\n",
      "Jump Model          0.0426        0.0475        0.8200        0.6554        0.7704\n",
      "Sparse Jump         0.0462        0.0197        0.8077        0.7943        0.8205\n",
      "\n",
      "Summary for mu=0.25 & P=150\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0021        0.0402        0.5281        0.4859        0.5110\n",
      "MLE k-means         0.0089        0.0334        0.5291        0.4857        0.5116\n",
      "Jump Model          0.0298       -0.0321        0.7749        0.4982        0.6842\n",
      "Sparse Jump         0.0268       -0.0133        0.7508        0.6885        0.7493\n",
      "\n",
      "Summary for mu=0.25 & P=300\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0531        0.0744        0.5284        0.5164        0.5234\n",
      "MLE k-means        -0.0251        0.0464        0.5324        0.5050        0.5211\n",
      "Jump Model         -0.0362        0.0834        0.7684        0.4691        0.6692\n",
      "Sparse Jump         0.0143        0.0072        0.7486        0.6244        0.7220\n",
      "\n",
      "Summary for mu=0.5 & P=15\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.4996       -0.2313        0.9197        0.9494        0.9093\n",
      "MLE k-means         0.5013       -0.1892        0.9010        0.9048        0.8858\n",
      "Jump Model          0.5010       -0.4633        0.9864        0.9758        0.9834\n",
      "Sparse Jump         0.5023       -0.4550        0.9852        0.9750        0.9825\n",
      "\n",
      "Summary for mu=0.5 & P=30\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.2550        0.0177        0.7372        0.7778        0.7350\n",
      "MLE k-means         0.2208        0.1666        0.5998        0.5880        0.5895\n",
      "Jump Model          0.2514       -0.2145        0.9801        0.9593        0.9736\n",
      "Sparse Jump         0.2529       -0.2098        0.9758        0.9897        0.9837\n",
      "\n",
      "Summary for mu=0.5 & P=60\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0661        0.1279        0.6047        0.5791        0.5875\n",
      "MLE k-means         0.0836        0.1271        0.5367        0.4876        0.5167\n",
      "Jump Model          0.1168       -0.0545        0.9292        0.8561        0.9063\n",
      "Sparse Jump         0.1093       -0.0342        0.9163        0.9233        0.9271\n",
      "\n",
      "Summary for mu=0.5 & P=150\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def             0.0202        0.0637        0.5332        0.4947        0.5171\n",
      "MLE k-means         0.0298        0.0539        0.5294        0.4850        0.5114\n",
      "Jump Model          0.0594       -0.0329        0.8445        0.6438        0.7780\n",
      "Sparse Jump         0.0591       -0.0286        0.8406        0.8676        0.8667\n",
      "\n",
      "Summary for mu=0.5 & P=300\n",
      "--------------------------------------------------------------------------\n",
      "               state0_mean   state1_mean          acc1          acc2           BAC\n",
      "MLE def            -0.0429        0.0844        0.5288        0.5148        0.5230\n",
      "MLE k-means        -0.0281        0.0704        0.5322        0.5067        0.5217\n",
      "Jump Model         -0.0021        0.0484        0.8177        0.5522        0.7275\n",
      "Sparse Jump         0.0089        0.0328        0.7903        0.6866        0.7680\n"
     ]
    }
   ],
   "source": [
    "def summarize_method(group, prefix):\n",
    "    \"\"\"\n",
    "    Extracts the mean of relevant columns for a given method prefix.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'state0_mean': group[f'{prefix}_state0_mean'].mean(),\n",
    "        'state1_mean': group[f'{prefix}_state1_mean'].mean(),\n",
    "        'acc1':        group[f'{prefix}_acc1'].mean(),\n",
    "        'acc2':        group[f'{prefix}_acc2'].mean(),\n",
    "        'BAC':         group[f'{prefix}_BAC'].mean()\n",
    "    }\n",
    "\n",
    "grouped = df_simulation.groupby(['mu', 'P'])\n",
    "\n",
    "for (m, p), group in grouped:\n",
    "    row_mle   = summarize_method(group, 'MLE')\n",
    "    row_mlek  = summarize_method(group, 'MLEK')\n",
    "    row_jump  = summarize_method(group, 'Jump')\n",
    "    row_sjump = summarize_method(group, 'SparseJump')\n",
    "\n",
    "    print(f\"\\nSummary for mu={m} & P={p}\")\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"{:<12s}  {:>12s}  {:>12s}  {:>12s}  {:>12s}  {:>12s}\".format(\n",
    "        \"\", \"state0_mean\", \"state1_mean\", \"acc1\", \"acc2\", \"BAC\"\n",
    "    ))\n",
    "\n",
    "    def fmt_row(method_name, r):\n",
    "        return \"{:<12s}  {:>12.4f}  {:>12.4f}  {:>12.4f}  {:>12.4f}  {:>12.4f}\".format(\n",
    "            method_name,\n",
    "            r['state0_mean'], r['state1_mean'], \n",
    "            r['acc1'], r['acc2'], r['BAC']\n",
    "        )\n",
    "\n",
    "    print(fmt_row(\"MLE def\", row_mle))\n",
    "    print(fmt_row(\"MLE k-means\", row_mlek))\n",
    "    print(fmt_row(\"Jump Model\", row_jump))\n",
    "    print(fmt_row(\"Sparse Jump\", row_sjump))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 statistical testing summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the metrics for which we want to create error values\n",
    "#   - state0_mean: true value is mu\n",
    "#   - state1_mean: true value is -mu\n",
    "#   - acc1, acc2, and BAC: we assume the ideal is 1.0 (or user-provided references)\n",
    "metric_list = [\"state0_mean\", \"state1_mean\", \"acc1\", \"acc2\", \"BAC\"]\n",
    "model_prefixes = [\"MLEK\", \"Jump\", \"SparseJump\"]\n",
    "\n",
    "# create a copy\n",
    "final_result_errors = df_simulation.copy()\n",
    "\n",
    "def compute_ref_values(row):\n",
    "    mu = row['mu']\n",
    "    return {\n",
    "        \"state0_mean\": mu,\n",
    "        \"state1_mean\": -mu,\n",
    "        # example references\n",
    "        \"acc1\": 0.992246,\n",
    "        \"acc2\": 0.921367,\n",
    "        \"BAC\": 0.956806\n",
    "    }\n",
    "\n",
    "refs = final_result_errors.apply(compute_ref_values, axis=1)\n",
    "\n",
    "for metric in metric_list:\n",
    "    for prefix in model_prefixes:\n",
    "        error_col = f\"{prefix}_{metric}_error\"\n",
    "        final_result_errors[error_col] = final_result_errors.apply(\n",
    "            lambda row: abs(row[f\"{prefix}_{metric}\"] - compute_ref_values(row)[metric]),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "grouped = final_result_errors.groupby(['mu', 'P'])\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "import numpy as np\n",
    "\n",
    "def two_sided_wilcoxon_p(diffs, atol=1e-10):\n",
    "    diffs = np.array(diffs)\n",
    "    diffs = diffs[~np.isnan(diffs)]\n",
    "    if len(diffs) == 0:\n",
    "        return 1.0\n",
    "    if np.allclose(diffs, 0, atol=atol):\n",
    "        return 1.0\n",
    "    try:\n",
    "        _, p = wilcoxon(diffs)\n",
    "        return p\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def one_sided_pval(diffs, p_two_sided):\n",
    "    if np.isnan(p_two_sided):\n",
    "        return np.nan\n",
    "    mean_diff = np.mean(diffs)\n",
    "    if mean_diff > 0:\n",
    "        return p_two_sided / 2\n",
    "    else:\n",
    "        return 1 - p_two_sided / 2\n",
    "\n",
    "for (mu_val, P_val), group in grouped:\n",
    "    table_rows = []\n",
    "    for metric in metric_list:\n",
    "        col_mlek = f\"MLEK_{metric}_error\"\n",
    "        col_jump = f\"Jump_{metric}_error\"\n",
    "        col_sparse = f\"SparseJump_{metric}_error\"\n",
    "\n",
    "        e_mlek = group[col_mlek]\n",
    "        e_jump = group[col_jump]\n",
    "        e_sparse = group[col_sparse]\n",
    "\n",
    "        mean_mlek = e_mlek.mean()\n",
    "        mean_jump = e_jump.mean()\n",
    "        mean_sparse = e_sparse.mean()\n",
    "\n",
    "        # Sparse < Jump\n",
    "        diff_sj = e_jump - e_sparse\n",
    "        p2_sj = two_sided_wilcoxon_p(diff_sj)\n",
    "        p1_sj = one_sided_pval(diff_sj, p2_sj)\n",
    "\n",
    "        # Jump < MLEK\n",
    "        diff_jm = e_mlek - e_jump\n",
    "        p2_jm = two_sided_wilcoxon_p(diff_jm)\n",
    "        p1_jm = one_sided_pval(diff_jm, p2_jm)\n",
    "\n",
    "        # Sparse < MLEK\n",
    "        diff_sm = e_mlek - e_sparse\n",
    "        p2_sm = two_sided_wilcoxon_p(diff_sm)\n",
    "        p1_sm = one_sided_pval(diff_sm, p2_sm)\n",
    "\n",
    "        table_rows.append({\n",
    "            \"Metric\": metric,\n",
    "            \"MLEK Mean Error\": mean_mlek,\n",
    "            \"Jump Mean Error\": mean_jump,\n",
    "            \"SparseJump Mean Error\": mean_sparse,\n",
    "            \"p (Sparse < Jump)\": p1_sj,\n",
    "            \"p (Jump < MLEK)\": p1_jm,\n",
    "            \"p (Sparse < MLEK)\": p1_sm\n",
    "        })\n",
    "    \n",
    "    wilcoxon_table = pd.DataFrame(table_rows)\n",
    "    print(f\"\\n=== Wilcoxon Test Results for mu = {mu_val} and P = {P_val} ===\")\n",
    "    print(wilcoxon_table.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames as CSV files if desired\n",
    "df_simulation.to_csv(\"df_simulation.csv\", index=False)\n",
    "df_grid_jump.to_csv(\"df_grid_jump.csv\", index=False)\n",
    "df_grid_sparse.to_csv(\"df_grid_sparse.csv\", index=False)\n",
    "df_wilcoxon.to_csv(\"df_wilcoxon.csv\", index=False)\n",
    "final_result_errors.to_csv(\"final_result_errors.csv\", index=False)\n",
    "\n",
    "print(\"All DataFrames have been saved as CSV files in the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
