{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# Hidden Markov Model utilities\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# PyPortfolioOpt\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models, expected_returns\n",
    "from pypfopt.black_litterman import BlackLittermanModel\n",
    "\n",
    "# Sparse Jump Model utilities\n",
    "from jumpmodels.sparse_jump import SparseJumpModel\n",
    "from jumpmodels.preprocess import StandardScalerPD, DataClipperStd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSETS = [\"Value\", \"Growth\", \"LowVol\", \"Size\", \"Momentum\", \"Quality\"]\n",
    "N_ASSETS = len(ASSETS)\n",
    "\n",
    "def simulate_1state_data(num_days, seed=None):\n",
    "    np_rng = np.random.default_rng(seed)\n",
    "    # For demonstration, these defaults remain in-sample-only:\n",
    "    SIM_MEAN_1STATE = 0.000461\n",
    "    SIM_SIG_1STATE  = 0.008388\n",
    "\n",
    "    corr = np.full((N_ASSETS, N_ASSETS), 0.185)\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    cov = np.outer(np.full(N_ASSETS, SIM_SIG_1STATE),\n",
    "                   np.full(N_ASSETS, SIM_SIG_1STATE)) * corr\n",
    "\n",
    "    rets = np_rng.multivariate_normal(\n",
    "        mean=np.full(N_ASSETS, SIM_MEAN_1STATE),\n",
    "        cov=cov,\n",
    "        size=num_days\n",
    "    )\n",
    "    return pd.DataFrame(rets, columns=ASSETS)\n",
    "\n",
    "def simulate_2state_data(num_days, seed=None):\n",
    "    np_rng = np.random.default_rng(seed)\n",
    "    transmat = np.array([[0.9976, 0.0024],\n",
    "                         [0.0232, 0.9768]])\n",
    "    mu_dict  = {0: 0.0006,   1: -0.000881}\n",
    "    sig_dict = {0: 0.00757, 1: 0.0163}\n",
    "\n",
    "    base_corr = np.full((N_ASSETS, N_ASSETS), 0.185)\n",
    "    np.fill_diagonal(base_corr, 1.0)\n",
    "\n",
    "    all_states = np.zeros((num_days, N_ASSETS), dtype=int)\n",
    "    for i in range(N_ASSETS):\n",
    "        s = np.zeros(num_days, dtype=int)\n",
    "        s[0] = np_rng.integers(2)\n",
    "        for t in range(1, num_days):\n",
    "            s[t] = np_rng.choice(2, p=transmat[s[t - 1]])\n",
    "        all_states[:, i] = s\n",
    "\n",
    "    rets = np.zeros((num_days, N_ASSETS))\n",
    "    for t in range(num_days):\n",
    "        mu_vec  = np.zeros(N_ASSETS)\n",
    "        sig_vec = np.zeros(N_ASSETS)\n",
    "        for i in range(N_ASSETS):\n",
    "            curr_state = all_states[t, i]\n",
    "            mu_vec[i]  = mu_dict[curr_state]\n",
    "            sig_vec[i] = sig_dict[curr_state]\n",
    "        cov_t = np.outer(sig_vec, sig_vec) * base_corr\n",
    "        rets[t] = np_rng.multivariate_normal(mean=mu_vec, cov=cov_t)\n",
    "\n",
    "    return pd.DataFrame(rets, columns=ASSETS), all_states\n",
    "\n",
    "def simulate_3state_data(num_days, seed=None):\n",
    "    np_rng = np.random.default_rng(seed)\n",
    "    transmat = np.array([\n",
    "        [0.9989, 0.0004, 0.0007],\n",
    "        [0.0089, 0.9904, 0.0007],\n",
    "        [0.0089, 0.0004, 0.9907]\n",
    "    ])\n",
    "    mu_list  = [0.0008, 0.0,     -0.003586]\n",
    "    sig_list = [0.0070, 0.0050,  0.01897]\n",
    "\n",
    "    base_corr = np.full((N_ASSETS, N_ASSETS), 0.185)\n",
    "    np.fill_diagonal(base_corr, 1.0)\n",
    "\n",
    "    all_states = np.zeros((num_days, N_ASSETS), dtype=int)\n",
    "    for i in range(N_ASSETS):\n",
    "        s = np.zeros(num_days, dtype=int)\n",
    "        s[0] = np_rng.integers(3)\n",
    "        for t in range(1, num_days):\n",
    "            s[t] = np_rng.choice(3, p=transmat[s[t - 1]])\n",
    "        all_states[:, i] = s\n",
    "\n",
    "    rets = np.zeros((num_days, N_ASSETS))\n",
    "    for t in range(num_days):\n",
    "        mu_vec  = np.zeros(N_ASSETS)\n",
    "        sig_vec = np.zeros(N_ASSETS)\n",
    "        for i in range(N_ASSETS):\n",
    "            st_i   = all_states[t, i]\n",
    "            mu_vec[i]  = mu_list[st_i]\n",
    "            sig_vec[i] = sig_list[st_i]\n",
    "        cov_t = np.outer(sig_vec, sig_vec) * base_corr\n",
    "        rets[t] = np_rng.multivariate_normal(mean=mu_vec, cov=cov_t)\n",
    "\n",
    "    return pd.DataFrame(rets, columns=ASSETS), all_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training Regime Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mle(observations, n_components=2, init_type='default', seed=None):\n",
    "    model = GaussianHMM(\n",
    "        n_components=n_components,\n",
    "        covariance_type='diag',\n",
    "        n_iter=100,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    if init_type == 'default':\n",
    "        model.startprob_ = np.array([1.0, 0.0])\n",
    "        model.transmat_  = np.array([\n",
    "            [0.9, 0.1],\n",
    "            [0.1, 0.9]\n",
    "        ])\n",
    "        model.means_  = np.zeros((n_components, observations.shape[1]))\n",
    "        model.covars_ = np.full((n_components, observations.shape[1]), 1e-10)\n",
    "        model.init_params = ''\n",
    "    elif init_type == 'kmeans':\n",
    "        km = KMeans(n_clusters=n_components, n_init=10, random_state=seed)\n",
    "        labels = km.fit_predict(observations)\n",
    "        means, covars = [], []\n",
    "        for i in range(n_components):\n",
    "            obs_i = observations[labels == i]\n",
    "            means.append(np.mean(obs_i, axis=0))\n",
    "            covars.append(np.var(obs_i, axis=0) + 1e-10)\n",
    "        model.startprob_ = np.ones(n_components) / n_components\n",
    "        model.transmat_  = np.ones((n_components, n_components)) / n_components\n",
    "        model.means_     = np.array(means)\n",
    "        model.covars_    = np.array(covars)\n",
    "        model.init_params = ''\n",
    "\n",
    "    model.fit(observations)\n",
    "    pred_states = model.predict(observations)\n",
    "    return model, pred_states\n",
    "\n",
    "def run_mle_default(observations, seed=None):\n",
    "    return run_mle(observations, init_type='default', seed=seed)\n",
    "\n",
    "def run_mle_kmeans(observations, seed=None):\n",
    "    return run_mle(observations, init_type='kmeans', seed=seed)\n",
    "\n",
    "def train_hmm_single_asset_default(series, n_components=2, random_state=42):\n",
    "    X = series.values.reshape(-1, 1)\n",
    "    model, _ = run_mle_default(X, seed=random_state)\n",
    "    return model\n",
    "\n",
    "def train_hmm_single_asset_kmeans(series, n_components=2, random_state=42):\n",
    "    X = series.values.reshape(-1, 1)\n",
    "    model, _ = run_mle_kmeans(X, seed=random_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Feature selection and SJM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sjm_features(factor_ser: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build strictly backward-looking features for a single factor 'factor_ser'.\n",
    "    Returns a DataFrame with 12 columns (EWMAs, RSI, Stoch, MACD, DownsideDev).\n",
    "    \"\"\"\n",
    "    factor_price = 100.0 * (1.0 + factor_ser).cumprod()\n",
    "\n",
    "    def ewma_return(returns, halflife):\n",
    "        return returns.ewm(halflife=halflife).mean()\n",
    "\n",
    "    def compute_rsi(price, window):\n",
    "        delta = price.diff()\n",
    "        gain  = delta.clip(lower=0)\n",
    "        loss  = -delta.clip(upper=0)\n",
    "        avg_gain = gain.rolling(window).mean()\n",
    "        avg_loss = loss.rolling(window).mean()\n",
    "        rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "        return 100.0 - (100.0 / (1.0 + rs))\n",
    "\n",
    "    def compute_stoch(price, window):\n",
    "        rolling_min = price.rolling(window).min()\n",
    "        rolling_max = price.rolling(window).max()\n",
    "        return 100.0 * (price - rolling_min) / (rolling_max - rolling_min)\n",
    "\n",
    "    def compute_macd(price, fast, slow):\n",
    "        ema_fast = price.ewm(halflife=fast).mean()\n",
    "        ema_slow = price.ewm(halflife=slow).mean()\n",
    "        return ema_fast - ema_slow\n",
    "\n",
    "    def compute_downside_dev_log(returns, window):\n",
    "        def _downside(subarray):\n",
    "            negatives = np.where(subarray < 0, subarray, 0.0)\n",
    "            return np.sqrt((negatives**2).mean())\n",
    "        dd = returns.rolling(window).apply(_downside, raw=True)\n",
    "        return np.log(dd.replace(0, np.nan))\n",
    "\n",
    "    feats = {}\n",
    "    for hl in [8, 21, 63]:\n",
    "        feats[f\"FactorRet_EWMA_{hl}\"] = ewma_return(factor_ser, hl)\n",
    "    for w in [8, 21, 63]:\n",
    "        feats[f\"RSI_{w}\"] = compute_rsi(factor_price, w)\n",
    "    for w in [8, 21, 63]:\n",
    "        feats[f\"Stoch%K_{w}\"] = compute_stoch(factor_price, w)\n",
    "\n",
    "    feats[\"MACD_8_21\"]   = compute_macd(factor_price, 8, 21)\n",
    "    feats[\"MACD_21_63\"]  = compute_macd(factor_price, 21, 63)\n",
    "    feats[\"DownsideDev_log_21\"] = compute_downside_dev_log(factor_ser, 21)\n",
    "    \n",
    "    return pd.DataFrame(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SJM\n",
    "def train_sjm_single_asset(series, n_components=2, max_feats=12, lam=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Train SJM on one asset, using the backward-looking features from above.\n",
    "    \"\"\"\n",
    "    feats_df = compute_sjm_features(series)\n",
    "    feats_df = feats_df.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    clipper = DataClipperStd(mul=3.0)\n",
    "    scaler  = StandardScalerPD()\n",
    "\n",
    "    X_clipped = clipper.fit_transform(feats_df)\n",
    "    X_scaled  = scaler.fit_transform(X_clipped)\n",
    "    X_arr = X_scaled.values\n",
    "\n",
    "    sjm = SparseJumpModel(\n",
    "        n_components=n_components,\n",
    "        max_feats=max_feats,\n",
    "        jump_penalty=lam,  # <- lam from the function arg\n",
    "        cont=False,\n",
    "        max_iter=20,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    sjm.fit(X_arr)\n",
    "\n",
    "    return sjm, clipper, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Allocation simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Backtest a static portfolio with single allocaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_portfolio(returns, weights, transaction_cost=0.0007):\n",
    "    \"\"\"\n",
    "    Backtest a static portfolio with a single allocation across the entire test period.\n",
    "    Includes an initial transaction cost.\n",
    "    \"\"\"\n",
    "    T = len(returns)\n",
    "    portfolio_vals = np.zeros(T)\n",
    "    cost_init = np.sum(np.abs(weights)) * transaction_cost\n",
    "    portfolio_vals[0] = 1.0 - cost_init\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        ret_t = returns.iloc[t].values\n",
    "        portfolio_vals[t + 1] = portfolio_vals[t] * (1.0 + np.dot(weights, ret_t))\n",
    "\n",
    "    return portfolio_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 Performance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_metrics(portfolio_vals, weight_history=None, annual_factor=250):\n",
    "    \"\"\"\n",
    "    Calculate performance stats on the final portfolio_vals series.\n",
    "    \"\"\"\n",
    "    pv = np.asarray(portfolio_vals)\n",
    "    rets = np.diff(pv) / pv[:-1]\n",
    "\n",
    "    ann_ret = rets.mean() * annual_factor\n",
    "    cum_ret = pv[-1]/pv[0] - 1\n",
    "    ann_vol = rets.std() * np.sqrt(annual_factor)\n",
    "\n",
    "    negative_rets = rets[rets < 0]\n",
    "    ddev = (negative_rets.std() * np.sqrt(annual_factor)) if len(negative_rets) > 0 else 0.0\n",
    "    max_dd = (pv / np.maximum.accumulate(pv) - 1).min()\n",
    "\n",
    "    sharpe = ann_ret / (ann_vol + 1e-12)\n",
    "    sortino = ann_ret / ddev if ddev > 1e-12 else np.nan\n",
    "    calmar  = ann_ret / abs(max_dd) if max_dd < 0 else np.nan\n",
    "\n",
    "    if weight_history is not None and len(weight_history) > 1:\n",
    "        turnovers = []\n",
    "        for t in range(1, len(weight_history)):\n",
    "            turnovers.append(np.sum(np.abs(weight_history[t] - weight_history[t-1])))\n",
    "        avg_turnover = np.mean(turnovers)\n",
    "    else:\n",
    "        avg_turnover = 0.0\n",
    "\n",
    "    return {\n",
    "        \"Annualized Return\": ann_ret,\n",
    "        \"Cumulative Return\": cum_ret,\n",
    "        \"Volatility\": ann_vol,\n",
    "        \"Downside Deviation\": ddev,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Sortino Ratio\": sortino,\n",
    "        \"Calmar Ratio\": calmar,\n",
    "        \"Turnover Rate\": avg_turnover,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Helper Function: get per-regime means & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regime_means_stds_single_asset(asset_series, regime_assignments):\n",
    "    \"\"\"\n",
    "    Returns two dicts:\n",
    "      means_dict = {state: mean_return_in_that_state}\n",
    "      stds_dict  = {state: std_return_in_that_state}\n",
    "    \"\"\"\n",
    "    unique_states = np.unique(regime_assignments)\n",
    "    regime_means = {}\n",
    "    regime_stds  = {}\n",
    "    for s in unique_states:\n",
    "        data_in_s = asset_series[regime_assignments == s]\n",
    "        if len(data_in_s) > 0:\n",
    "            regime_means[s] = data_in_s.mean()\n",
    "            regime_stds[s]  = data_in_s.std()\n",
    "        else:\n",
    "            # fallback if empty\n",
    "            regime_means[s] = asset_series.mean()\n",
    "            regime_stds[s]  = asset_series.std()\n",
    "    return regime_means, regime_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Equal Unconditional Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_equal_unconditional_prior(df_train):\n",
    "    \"\"\"\n",
    "    Build an 'equal unconditional prior' for BL using approximate known unconditional values.\n",
    "    For demonstration, we fix SIM_MEAN_1STATE=0.000461, SIM_SIG_1STATE=0.008388, correlation=0.185.\n",
    "    \"\"\"\n",
    "    SIM_MEAN_1STATE = 0.000461\n",
    "    SIM_SIG_1STATE  = 0.008388\n",
    "    TRUE_CORR       = 0.185\n",
    "\n",
    "    n_assets = df_train.shape[1]\n",
    "    uniform_corr = np.full((n_assets, n_assets), TRUE_CORR)\n",
    "    np.fill_diagonal(uniform_corr, 1.0)\n",
    "\n",
    "    cov_flat = (SIM_SIG_1STATE**2) * uniform_corr\n",
    "\n",
    "    assets = df_train.columns\n",
    "    pi_series = pd.Series(np.full(n_assets, SIM_MEAN_1STATE), index=assets)\n",
    "    cov_df = pd.DataFrame(cov_flat, index=assets, columns=assets)\n",
    "    return pi_series, cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.0 Regime-Based BL with the 'Equal Unconditional Prior'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regime_based_bl_backtest_flatprior(\n",
    "    df_test,\n",
    "    states_test,\n",
    "    regime_means_list,\n",
    "    regime_stds_list,\n",
    "    flat_pi,\n",
    "    flat_cov,\n",
    "    train_means_per_asset,\n",
    "    train_stds_per_asset,\n",
    "    transaction_cost=0.0007,\n",
    "    risk_free_rate=0.02/252,\n",
    "    bl_tau=0.05,\n",
    "    fallback_bear_mean=-0.0005,  # Typical bear return\n",
    "    fallback_bear_std=0.015      # Typical bear volatility\n",
    "):\n",
    "    T_test = len(df_test)\n",
    "    n_assets = len(df_test.columns)\n",
    "    assets = df_test.columns\n",
    "\n",
    "    diag_std = np.sqrt(np.diag(flat_cov))\n",
    "    corr_matrix = flat_cov / (np.outer(diag_std, diag_std) + 1e-12)\n",
    "\n",
    "    portfolio_vals = np.zeros(T_test)\n",
    "    portfolio_vals[0] = 1.0  # Start day with $1\n",
    "\n",
    "    weight_history = np.zeros((T_test, n_assets))\n",
    "    w_prev = np.ones(n_assets) / n_assets  # Start equally weighted\n",
    "    weight_history[0] = w_prev\n",
    "\n",
    "    for t in range(1, T_test):\n",
    "        # Identify regime from day (t-1)\n",
    "        view_vector = np.zeros(n_assets)\n",
    "        for i in range(n_assets):\n",
    "            current_regime = states_test[t - 1, i]\n",
    "            # Use fallback if regime not identified in training\n",
    "            if current_regime in regime_means_list[i]:\n",
    "                mean_i = regime_means_list[i][current_regime]\n",
    "            else:\n",
    "                mean_i = fallback_bear_mean\n",
    "            view_vector[i] = mean_i\n",
    "\n",
    "        # Build daily covariance from correlation + regime-based volatilities\n",
    "        day_vols = np.zeros(n_assets)\n",
    "        for i in range(n_assets):\n",
    "            current_regime = states_test[t - 1, i]\n",
    "            if current_regime in regime_stds_list[i]:\n",
    "                day_vols[i] = regime_stds_list[i][current_regime]\n",
    "            else:\n",
    "                day_vols[i] = fallback_bear_std\n",
    "        daily_cov = corr_matrix * np.outer(day_vols, day_vols)\n",
    "\n",
    "        # Build Black-Litterman model for day t\n",
    "        bl = BlackLittermanModel(\n",
    "            cov_matrix    = daily_cov,\n",
    "            pi            = flat_pi,\n",
    "            absolute_views= dict(zip(assets, view_vector)),\n",
    "            tau           = bl_tau,\n",
    "            risk_aversion = 1.0\n",
    "        )\n",
    "        bl_rets = bl.bl_returns()\n",
    "        bl_cov  = bl.bl_cov()\n",
    "\n",
    "        ef = EfficientFrontier(bl_rets, bl_cov, weight_bounds=(0, 1), solver=\"SCS\")\n",
    "        try:\n",
    "            w_dict = ef.max_sharpe(risk_free_rate=risk_free_rate)\n",
    "        except ValueError:\n",
    "            w_dict = ef.min_volatility()\n",
    "        w_array = np.array([w_dict[a] for a in assets])\n",
    "\n",
    "        # Transaction cost & portfolio update\n",
    "        ret_t_minus_1 = df_test.iloc[t - 1].values\n",
    "        gross_growth  = portfolio_vals[t - 1] * (1.0 + np.dot(w_prev, ret_t_minus_1))\n",
    "        traded_fraction = np.sum(np.abs(w_array - w_prev))\n",
    "        cost = gross_growth * traded_fraction * transaction_cost\n",
    "\n",
    "        portfolio_vals[t] = gross_growth - cost\n",
    "        weight_history[t] = w_array\n",
    "        w_prev = w_array\n",
    "\n",
    "    return portfolio_vals, weight_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Wrapper to run all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_weight_allocation(n_assets):\n",
    "    return np.ones(n_assets)/n_assets\n",
    "\n",
    "def inverse_vol_weights(returns):\n",
    "    stds = returns.std(axis=0).values + 1e-12\n",
    "    w = 1.0/stds\n",
    "    return w / w.sum()\n",
    "\n",
    "def static_mvo_allocation(returns, risk_free_rate=0.02/252):\n",
    "    mu = expected_returns.mean_historical_return(returns, frequency=250)\n",
    "    raw_cov = risk_models.sample_cov(returns)\n",
    "    ridge_lambda = 1e-5\n",
    "    cov = raw_cov + np.eye(len(raw_cov)) * ridge_lambda\n",
    "\n",
    "    try:\n",
    "        ef = EfficientFrontier(mu, cov, weight_bounds=(0, 1), solver=\"SCS\")\n",
    "        ef_weights = ef.max_sharpe(risk_free_rate=risk_free_rate)\n",
    "    except ValueError as e:\n",
    "        print(f\"Falling back to min_volatility due to: {e}\")\n",
    "        ef = EfficientFrontier(mu, cov, weight_bounds=(0, 1), solver=\"SCS\")\n",
    "        ef_weights = ef.min_volatility()\n",
    "\n",
    "    return ef.clean_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allocation(\n",
    "    df,\n",
    "    lam_sjm=50,\n",
    "    risk_free_rate=0.02/252,\n",
    "    transaction_cost=0.0007,\n",
    "    bl_tau=0.05\n",
    "):\n",
    "    split_idx = int(len(df) * 0.8)\n",
    "    df_train = df.iloc[:split_idx]\n",
    "    df_test  = df.iloc[split_idx:]\n",
    "\n",
    "    # --- Train per-asset models ---\n",
    "    hmm_models_default = []\n",
    "    hmm_models_kmeans  = []\n",
    "    sjm_models         = []\n",
    "    sjm_clippers       = []\n",
    "    sjm_scalers        = []\n",
    "\n",
    "    hmm_states_default_train = np.zeros((split_idx, N_ASSETS), dtype=int)\n",
    "    hmm_states_kmeans_train  = np.zeros((split_idx, N_ASSETS), dtype=int)\n",
    "    sjm_states_train         = np.zeros((split_idx, N_ASSETS), dtype=int)\n",
    "\n",
    "    for i, asset in enumerate(ASSETS):\n",
    "        series_train = df_train[asset]\n",
    "\n",
    "        # HMM default\n",
    "        hmm_d = train_hmm_single_asset_default(series_train)\n",
    "        st_def = hmm_d.predict(series_train.values.reshape(-1, 1))\n",
    "        hmm_models_default.append(hmm_d)\n",
    "        hmm_states_default_train[:, i] = st_def\n",
    "\n",
    "        # HMM kmeans\n",
    "        hmm_k = train_hmm_single_asset_kmeans(series_train)\n",
    "        st_km = hmm_k.predict(series_train.values.reshape(-1, 1))\n",
    "        hmm_models_kmeans.append(hmm_k)\n",
    "        hmm_states_kmeans_train[:, i] = st_km\n",
    "\n",
    "        # SJM\n",
    "        sjm_mod, sjm_clip, sjm_scale = train_sjm_single_asset(\n",
    "            series_train, n_components=2, max_feats=12, lam=lam_sjm\n",
    "        )\n",
    "        feats_train = compute_sjm_features(series_train).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        X_train_clip = sjm_clip.transform(feats_train)\n",
    "        X_train_scl  = sjm_scale.transform(X_train_clip)\n",
    "        st_sjm = sjm_mod.predict(X_train_scl)\n",
    "\n",
    "        sjm_models.append(sjm_mod)\n",
    "        sjm_clippers.append(sjm_clip)\n",
    "        sjm_scalers.append(sjm_scale)\n",
    "        sjm_states_train[:, i] = st_sjm\n",
    "\n",
    "    # --- In-sample regime means & stds ---\n",
    "    hmm_regime_means_default = []\n",
    "    hmm_regime_stds_default  = []\n",
    "    hmm_regime_means_kmeans  = []\n",
    "    hmm_regime_stds_kmeans   = []\n",
    "    sjm_regime_means         = []\n",
    "    sjm_regime_stds          = []\n",
    "\n",
    "    train_means_per_asset = []\n",
    "    train_stds_per_asset  = []\n",
    "\n",
    "    for i in range(N_ASSETS):\n",
    "        asset_train = df_train.iloc[:, i]\n",
    "        train_means_per_asset.append(asset_train.mean())\n",
    "        train_stds_per_asset.append(asset_train.std())\n",
    "\n",
    "        # HMM default\n",
    "        m_def, s_def = get_regime_means_stds_single_asset(asset_train, hmm_states_default_train[:, i])\n",
    "        hmm_regime_means_default.append(m_def)\n",
    "        hmm_regime_stds_default.append(s_def)\n",
    "\n",
    "        # HMM kmeans\n",
    "        m_km, s_km = get_regime_means_stds_single_asset(asset_train, hmm_states_kmeans_train[:, i])\n",
    "        hmm_regime_means_kmeans.append(m_km)\n",
    "        hmm_regime_stds_kmeans.append(s_km)\n",
    "\n",
    "        # SJM\n",
    "        m_sjm, s_sjm = get_regime_means_stds_single_asset(asset_train, sjm_states_train[:, i])\n",
    "        sjm_regime_means.append(m_sjm)\n",
    "        sjm_regime_stds.append(s_sjm)\n",
    "\n",
    "    # --- Predict states on test (partial day-by-day) ---\n",
    "    T_test = len(df_test)\n",
    "    hmm_states_default_test = np.zeros((T_test, N_ASSETS), dtype=int)\n",
    "    hmm_states_kmeans_test  = np.zeros((T_test, N_ASSETS), dtype=int)\n",
    "    sjm_states_test         = np.zeros((T_test, N_ASSETS), dtype=int)\n",
    "\n",
    "    # Full series (train + test) for partial inference\n",
    "    for i, asset in enumerate(ASSETS):\n",
    "        full_series = pd.concat([df_train[asset], df_test[asset]], axis=0).reset_index(drop=True)\n",
    "\n",
    "        # HMM default\n",
    "        for t in range(T_test):\n",
    "            # Safely slice up to (split_idx + t + 1), but not beyond total length\n",
    "            end_idx = min(split_idx + t + 1, len(full_series))\n",
    "            partial_data = full_series.iloc[:end_idx].values.reshape(-1, 1)\n",
    "            partial_states = hmm_models_default[i].predict(partial_data)\n",
    "            hmm_states_default_test[t, i] = partial_states[-1]\n",
    "\n",
    "        # HMM kmeans\n",
    "        for t in range(T_test):\n",
    "            end_idx = min(split_idx + t + 1, len(full_series))\n",
    "            partial_data = full_series.iloc[:end_idx].values.reshape(-1, 1)\n",
    "            partial_states = hmm_models_kmeans[i].predict(partial_data)\n",
    "            hmm_states_kmeans_test[t, i] = partial_states[-1]\n",
    "\n",
    "        # SJM\n",
    "        feats_full = compute_sjm_features(full_series).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        X_full_clip = sjm_clippers[i].transform(feats_full)\n",
    "        X_full_scl  = sjm_scalers[i].transform(X_full_clip)\n",
    "\n",
    "        for t in range(T_test):\n",
    "            end_idx = min(split_idx + t + 1, len(full_series))\n",
    "            partial_X = X_full_scl[:end_idx]\n",
    "            partial_states = sjm_models[i].predict(partial_X)\n",
    "            # Use positional indexing if partial_states is a pandas Series.\n",
    "            if isinstance(partial_states, pd.Series):\n",
    "                sjm_states_test[t, i] = partial_states.iloc[-1]\n",
    "            else:\n",
    "                sjm_states_test[t, i] = partial_states[-1]\n",
    "\n",
    "\n",
    "    # --- Build flat unconditional prior ---\n",
    "    flat_pi, flat_cov = build_equal_unconditional_prior(df_train)\n",
    "\n",
    "    # --- Evaluate Strategies ---\n",
    "\n",
    "    # (A) Equal Weight\n",
    "    w_ew = equal_weight_allocation(N_ASSETS)\n",
    "    pv_ew = backtest_portfolio(df_test, w_ew, transaction_cost=transaction_cost)\n",
    "    w_hist_ew = np.tile(w_ew, (T_test, 1))\n",
    "\n",
    "    # (B) Inverse Vol\n",
    "    w_iv = inverse_vol_weights(df_test)\n",
    "    pv_iv = backtest_portfolio(df_test, w_iv, transaction_cost=transaction_cost)\n",
    "    w_hist_iv = np.tile(w_iv, (T_test, 1))\n",
    "\n",
    "    # (C) Static MVO\n",
    "    w_mvo_dict = static_mvo_allocation(df_train, risk_free_rate=risk_free_rate)\n",
    "    w_mvo_arr = np.array([w_mvo_dict[a] for a in df_train.columns])\n",
    "    pv_mvo = backtest_portfolio(df_test, w_mvo_arr, transaction_cost=transaction_cost)\n",
    "    w_hist_mvo = np.tile(w_mvo_arr, (T_test, 1))\n",
    "\n",
    "    # (D) HMM-BL (Default)\n",
    "    pv_hmmbl_def, w_hmmbl_def = regime_based_bl_backtest_flatprior(\n",
    "        df_test,\n",
    "        hmm_states_default_test,\n",
    "        hmm_regime_means_default,\n",
    "        hmm_regime_stds_default,\n",
    "        flat_pi,\n",
    "        flat_cov,\n",
    "        train_means_per_asset,\n",
    "        train_stds_per_asset,\n",
    "        transaction_cost=transaction_cost,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        bl_tau=bl_tau\n",
    "    )\n",
    "\n",
    "    # (E) HMM-BL (KMeans)\n",
    "    pv_hmmbl_km, w_hmmbl_km = regime_based_bl_backtest_flatprior(\n",
    "        df_test,\n",
    "        hmm_states_kmeans_test,\n",
    "        hmm_regime_means_kmeans,\n",
    "        hmm_regime_stds_kmeans,\n",
    "        flat_pi,\n",
    "        flat_cov,\n",
    "        train_means_per_asset,\n",
    "        train_stds_per_asset,\n",
    "        transaction_cost=transaction_cost,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        bl_tau=bl_tau\n",
    "    )\n",
    "\n",
    "    # (F) SJM-BL\n",
    "    pv_sjmbl, w_sjmbl = regime_based_bl_backtest_flatprior(\n",
    "        df_test,\n",
    "        sjm_states_test,\n",
    "        sjm_regime_means,\n",
    "        sjm_regime_stds,\n",
    "        flat_pi,\n",
    "        flat_cov,\n",
    "        train_means_per_asset,\n",
    "        train_stds_per_asset,\n",
    "        transaction_cost=transaction_cost,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        bl_tau=bl_tau\n",
    "    )\n",
    "\n",
    "    perf = {\n",
    "        \"EW\": compute_performance_metrics(pv_ew, w_hist_ew),\n",
    "        \"IV\": compute_performance_metrics(pv_iv, w_hist_iv),\n",
    "        \"MVO\": compute_performance_metrics(pv_mvo, w_hist_mvo),\n",
    "        \"HMM-BL-Default\": compute_performance_metrics(pv_hmmbl_def, w_hmmbl_def),\n",
    "        \"HMM-BL-KMeans\":  compute_performance_metrics(pv_hmmbl_km, w_hmmbl_km),\n",
    "        \"SJM-BL\":         compute_performance_metrics(pv_sjmbl, w_sjmbl)\n",
    "    }\n",
    "\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. FUll scenario 1-state, 2-state, 3-state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario_123(\n",
    "    T_sim=1000,\n",
    "    lam_sjm=50,\n",
    "    risk_free_rate=0.02/252,\n",
    "    transaction_cost=0.0007,\n",
    "    bl_tau=0.05,\n",
    "    seed1=None,\n",
    "    seed2=None,\n",
    "    seed3=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate & run 1-state, 2-state, 3-state data sets.\n",
    "    \"\"\"\n",
    "    df1_full = simulate_1state_data(T_sim, seed=seed1)\n",
    "    perf_1 = run_allocation(\n",
    "        df1_full,\n",
    "        lam_sjm=lam_sjm,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        transaction_cost=transaction_cost,\n",
    "        bl_tau=bl_tau\n",
    "    )\n",
    "\n",
    "    df2_full, _ = simulate_2state_data(T_sim, seed=seed2)\n",
    "    perf_2 = run_allocation(\n",
    "        df2_full,\n",
    "        lam_sjm=lam_sjm,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        transaction_cost=transaction_cost,\n",
    "        bl_tau=bl_tau\n",
    "    )\n",
    "\n",
    "    df3_full, _ = simulate_3state_data(T_sim, seed=seed3)\n",
    "    perf_3 = run_allocation(\n",
    "        df3_full,\n",
    "        lam_sjm=lam_sjm,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        transaction_cost=transaction_cost,\n",
    "        bl_tau=bl_tau\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"1state\": perf_1,\n",
    "        \"2state\": perf_2,\n",
    "        \"3state\": perf_3\n",
    "    }\n",
    "\n",
    "\n",
    "def single_monte_carlo_run(\n",
    "    run_id,\n",
    "    T_sim=1000,\n",
    "    lam_sjm=50,\n",
    "    risk_free_rate=0.02/252,\n",
    "    transaction_cost=0.0007,\n",
    "    bl_tau=0.05\n",
    "):\n",
    "    print(f\"Running simulation {run_id}...\")\n",
    "    seed_for_1state = run_id * 1000 + 11\n",
    "    seed_for_2state = run_id * 1000 + 22\n",
    "    seed_for_3state = run_id * 1000 + 33\n",
    "\n",
    "    results = run_scenario_123(\n",
    "        T_sim=T_sim,\n",
    "        lam_sjm=lam_sjm,\n",
    "        risk_free_rate=risk_free_rate,\n",
    "        transaction_cost=transaction_cost,\n",
    "        bl_tau=bl_tau,\n",
    "        seed1=seed_for_1state,\n",
    "        seed2=seed_for_2state,\n",
    "        seed3=seed_for_3state\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_monte_carlo_study(\n",
    "    n_runs=10,\n",
    "    T_sim=1000,\n",
    "    lam_sjm=50,\n",
    "    risk_free_rate=0.02/252,\n",
    "    transaction_cost=0.0007,\n",
    "    bl_tau=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs multiple replications in parallel. Then does Wilcoxon test on Sharpe Ratios.\n",
    "    \"\"\"\n",
    "    n_cores = multiprocessing.cpu_count()\n",
    "    print(f\"detected {n_cores} cores\")\n",
    "\n",
    "    all_results = Parallel(n_jobs=n_cores)(\n",
    "        delayed(single_monte_carlo_run)(\n",
    "            i+1, T_sim, lam_sjm, risk_free_rate, transaction_cost, bl_tau\n",
    "        ) \n",
    "        for i in range(n_runs)\n",
    "    )\n",
    "\n",
    "    # Strategies\n",
    "    strategies = [\"EW\", \"IV\", \"MVO\", \"HMM-BL-Default\", \"HMM-BL-KMeans\", \"SJM-BL\"]\n",
    "    scenarios  = [\"1state\", \"2state\", \"3state\"]\n",
    "\n",
    "    # Collect results\n",
    "    sharpe_data = {sc: {st: [] for st in strategies} for sc in scenarios}\n",
    "    all_metrics = {sc: {} for sc in scenarios}\n",
    "    for sc in scenarios:\n",
    "        all_metrics[sc] = {}\n",
    "        for st in strategies:\n",
    "            all_metrics[sc][st] = {\n",
    "                \"Annualized Return\": [],\n",
    "                \"Cumulative Return\": [],\n",
    "                \"Volatility\": [],\n",
    "                \"Downside Deviation\": [],\n",
    "                \"Max Drawdown\": [],\n",
    "                \"Sharpe Ratio\": [],\n",
    "                \"Sortino Ratio\": [],\n",
    "                \"Calmar Ratio\": [],\n",
    "                \"Turnover Rate\": [],\n",
    "            }\n",
    "\n",
    "    # Gather distribution of metrics\n",
    "    for run_res in all_results:\n",
    "        for sc in scenarios:\n",
    "            for st in strategies:\n",
    "                metrics_dict = run_res[sc][st]\n",
    "                sharpe_data[sc][st].append(metrics_dict[\"Sharpe Ratio\"])\n",
    "                for mkey in all_metrics[sc][st]:\n",
    "                    all_metrics[sc][st][mkey].append(metrics_dict[mkey])\n",
    "\n",
    "    # Wilcoxon test: SJM-BL vs others (Sharpe)\n",
    "    print(\"\\n==== Wilcoxon Tests (SJM-BL vs. others) ====\")\n",
    "    wilcoxon_rows = []\n",
    "    for sc in scenarios:\n",
    "        sjm_sharpes = sharpe_data[sc][\"SJM-BL\"]\n",
    "        for st in strategies:\n",
    "            if st == \"SJM-BL\":\n",
    "                continue\n",
    "            other_sharpes = sharpe_data[sc][st]\n",
    "            try:\n",
    "                stat, pval = wilcoxon(sjm_sharpes, other_sharpes, alternative='two-sided')\n",
    "            except ValueError:\n",
    "                stat, pval = np.nan, np.nan\n",
    "            print(f\"{sc} | SJM-BL vs {st}: stat={stat:.4f}, p={pval:.4g}\")\n",
    "            wilcoxon_rows.append({\n",
    "                \"Scenario\": sc,\n",
    "                \"Comparison\": f\"SJM-BL vs {st}\",\n",
    "                \"Statistic\": stat,\n",
    "                \"p-value\": pval\n",
    "            })\n",
    "\n",
    "    df_wilcoxon = pd.DataFrame(wilcoxon_rows)\n",
    "    print(\"\\nWilcoxon Results Table:\")\n",
    "    print(df_wilcoxon.to_string(index=False))\n",
    "\n",
    "    # Print average metrics\n",
    "    print(\"\\n==== Average Performance Metrics (across runs) ====\")\n",
    "    for sc in scenarios:\n",
    "        rows = []\n",
    "        for st in strategies:\n",
    "            metric_means = {}\n",
    "            for mkey, vals in all_metrics[sc][st].items():\n",
    "                metric_means[mkey] = np.mean(vals)\n",
    "            row = {\"Strategy\": st}\n",
    "            row.update(metric_means)\n",
    "            rows.append(row)\n",
    "        df_avg = pd.DataFrame(rows)\n",
    "        df_avg.set_index(\"Strategy\", inplace=True)\n",
    "        print(f\"\\n--- {sc.upper()} ---\")\n",
    "        print(df_avg.to_string())\n",
    "\n",
    "    return sharpe_data, all_metrics, all_results, df_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Exectution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 8 cores\n",
      "\n",
      "==== Wilcoxon Tests (SJM-BL vs. others) ====\n",
      "1state | SJM-BL vs EW: stat=0.0000, p=0.03125\n",
      "1state | SJM-BL vs IV: stat=0.0000, p=0.03125\n",
      "1state | SJM-BL vs MVO: stat=10.0000, p=1\n",
      "1state | SJM-BL vs HMM-BL-Default: stat=0.0000, p=0.03125\n",
      "1state | SJM-BL vs HMM-BL-KMeans: stat=0.0000, p=0.03125\n",
      "2state | SJM-BL vs EW: stat=6.0000, p=0.4375\n",
      "2state | SJM-BL vs IV: stat=6.0000, p=0.4375\n",
      "2state | SJM-BL vs MVO: stat=3.0000, p=0.1562\n",
      "2state | SJM-BL vs HMM-BL-Default: stat=0.0000, p=0.03125\n",
      "2state | SJM-BL vs HMM-BL-KMeans: stat=0.0000, p=0.03125\n",
      "3state | SJM-BL vs EW: stat=5.0000, p=0.3125\n",
      "3state | SJM-BL vs IV: stat=8.0000, p=0.6875\n",
      "3state | SJM-BL vs MVO: stat=7.0000, p=0.5625\n",
      "3state | SJM-BL vs HMM-BL-Default: stat=0.0000, p=0.03125\n",
      "3state | SJM-BL vs HMM-BL-KMeans: stat=10.0000, p=1\n",
      "\n",
      "Wilcoxon Results Table:\n",
      "Scenario               Comparison  Statistic  p-value\n",
      "  1state             SJM-BL vs EW        0.0  0.03125\n",
      "  1state             SJM-BL vs IV        0.0  0.03125\n",
      "  1state            SJM-BL vs MVO       10.0  1.00000\n",
      "  1state SJM-BL vs HMM-BL-Default        0.0  0.03125\n",
      "  1state  SJM-BL vs HMM-BL-KMeans        0.0  0.03125\n",
      "  2state             SJM-BL vs EW        6.0  0.43750\n",
      "  2state             SJM-BL vs IV        6.0  0.43750\n",
      "  2state            SJM-BL vs MVO        3.0  0.15625\n",
      "  2state SJM-BL vs HMM-BL-Default        0.0  0.03125\n",
      "  2state  SJM-BL vs HMM-BL-KMeans        0.0  0.03125\n",
      "  3state             SJM-BL vs EW        5.0  0.31250\n",
      "  3state             SJM-BL vs IV        8.0  0.68750\n",
      "  3state            SJM-BL vs MVO        7.0  0.56250\n",
      "  3state SJM-BL vs HMM-BL-Default        0.0  0.03125\n",
      "  3state  SJM-BL vs HMM-BL-KMeans       10.0  1.00000\n",
      "\n",
      "==== Average Performance Metrics (across runs) ====\n",
      "\n",
      "--- 1STATE ---\n",
      "                Annualized Return  Cumulative Return  Volatility  Downside Deviation  Max Drawdown  Sharpe Ratio  Sortino Ratio  Calmar Ratio  Turnover Rate\n",
      "Strategy                                                                                                                                                    \n",
      "EW                       0.132262           0.695017    0.074858            0.043428     -0.088300      1.765780       3.089376      1.693497       0.000000\n",
      "IV                       0.132243           0.694875    0.074825            0.043445     -0.088350      1.766402       3.087837      1.693564       0.000000\n",
      "MVO                      0.128577           0.677166    0.094516            0.055086     -0.116461      1.362675       2.366761      1.231088       0.000000\n",
      "HMM-BL-Default           0.131122           0.685518    0.076328            0.044839     -0.087297      1.712092       2.940552      1.697303       0.000258\n",
      "HMM-BL-KMeans           -0.015923          -0.072948    0.096184            0.058451     -0.248680     -0.166806      -0.273795     -0.045893       1.193830\n",
      "SJM-BL                   0.116723           0.605878    0.089932            0.054713     -0.138909      1.319183       2.210552      1.170216       0.040640\n",
      "\n",
      "--- 2STATE ---\n",
      "                Annualized Return  Cumulative Return  Volatility  Downside Deviation  Max Drawdown  Sharpe Ratio  Sortino Ratio  Calmar Ratio  Turnover Rate\n",
      "Strategy                                                                                                                                                    \n",
      "EW                       0.107070           0.545036    0.079912            0.048260     -0.106564      1.368192       2.289457      1.069144       0.000000\n",
      "IV                       0.111536           0.571421    0.078811            0.047424     -0.099114      1.441347       2.411133      1.162520       0.000000\n",
      "MVO                      0.092474           0.465229    0.097563            0.063841     -0.150417      0.965127       1.485989      0.854048       0.000000\n",
      "HMM-BL-Default           0.136508           0.721072    0.074703            0.044184     -0.076375      1.831718       3.110596      1.829133       0.019350\n",
      "HMM-BL-KMeans            0.137364           0.727032    0.073127            0.043282     -0.074309      1.884326       3.185141      2.015840       0.022523\n",
      "SJM-BL                   0.121016           0.614720    0.090618            0.056129     -0.100710      1.352947       2.212523      1.282344       0.040470\n",
      "\n",
      "--- 3STATE ---\n",
      "                Annualized Return  Cumulative Return  Volatility  Downside Deviation  Max Drawdown  Sharpe Ratio  Sortino Ratio  Calmar Ratio  Turnover Rate\n",
      "Strategy                                                                                                                                                    \n",
      "EW                       0.132551           0.719990    0.068637            0.040921     -0.076899      2.002075       3.451898      2.499425       0.000000\n",
      "IV                       0.144255           0.792920    0.066186            0.038941     -0.060982      2.212600       3.830526      3.002332       0.000000\n",
      "MVO                      0.147867           0.806064    0.076568            0.046119     -0.079109      1.968120       3.329709      2.231997       0.000000\n",
      "HMM-BL-Default           0.174766           1.010465    0.063169            0.036713     -0.047470      2.765751       4.797225      3.995742       0.003348\n",
      "HMM-BL-KMeans            0.130519           0.761099    0.071800            0.043291     -0.092643      2.018646       3.518638      2.968606       0.310988\n",
      "SJM-BL                   0.161007           0.918102    0.070165            0.041505     -0.065928      2.302641       3.952994      2.978162       0.025370\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Centralized parameter configuration\n",
    "    config = {\n",
    "        \"n_simulations\": 6,\n",
    "        \"T_sim\": 5000,\n",
    "        \"risk_free_rate\": 0.02 / 252,\n",
    "        \"transaction_cost\": 0.0005,\n",
    "        \"bl_tau\": 0.05,\n",
    "        \"lam_sjm\": 50,\n",
    "    }\n",
    "\n",
    "    # Run the Monte Carlo study using all config values\n",
    "    sharpe_data, all_metrics, all_runs, df_wilcoxon = run_monte_carlo_study(\n",
    "        n_runs=config[\"n_simulations\"],\n",
    "        T_sim=config[\"T_sim\"],\n",
    "        lam_sjm=config[\"lam_sjm\"],\n",
    "        risk_free_rate=config[\"risk_free_rate\"],\n",
    "        transaction_cost=config[\"transaction_cost\"],\n",
    "        bl_tau=config[\"bl_tau\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 8 cores\n",
      "\n",
      "==== Wilcoxon Tests (SJM-BL vs. others) ====\n",
      "1state | SJM-BL vs EW: stat=3.0000, p=0.1562\n",
      "1state | SJM-BL vs IV: stat=4.0000, p=0.2188\n",
      "1state | SJM-BL vs MVO: stat=4.0000, p=0.2188\n",
      "1state | SJM-BL vs HMM-BL-Default: stat=8.0000, p=0.6875\n",
      "1state | SJM-BL vs HMM-BL-KMeans: stat=0.0000, p=0.03125\n",
      "2state | SJM-BL vs EW: stat=10.0000, p=1\n",
      "2state | SJM-BL vs IV: stat=9.0000, p=0.8438\n",
      "2state | SJM-BL vs MVO: stat=7.0000, p=0.5625\n",
      "2state | SJM-BL vs HMM-BL-Default: stat=7.0000, p=0.5625\n",
      "2state | SJM-BL vs HMM-BL-KMeans: stat=2.0000, p=0.09375\n",
      "3state | SJM-BL vs EW: stat=3.0000, p=0.1562\n",
      "3state | SJM-BL vs IV: stat=3.0000, p=0.1562\n",
      "3state | SJM-BL vs MVO: stat=5.0000, p=0.3125\n",
      "3state | SJM-BL vs HMM-BL-Default: stat=6.0000, p=0.4375\n",
      "3state | SJM-BL vs HMM-BL-KMeans: stat=0.0000, p=0.03125\n",
      "\n",
      "Wilcoxon Results Table:\n",
      "Scenario               Comparison  Statistic  p-value\n",
      "  1state             SJM-BL vs EW        3.0  0.15625\n",
      "  1state             SJM-BL vs IV        4.0  0.21875\n",
      "  1state            SJM-BL vs MVO        4.0  0.21875\n",
      "  1state SJM-BL vs HMM-BL-Default        8.0  0.68750\n",
      "  1state  SJM-BL vs HMM-BL-KMeans        0.0  0.03125\n",
      "  2state             SJM-BL vs EW       10.0  1.00000\n",
      "  2state             SJM-BL vs IV        9.0  0.84375\n",
      "  2state            SJM-BL vs MVO        7.0  0.56250\n",
      "  2state SJM-BL vs HMM-BL-Default        7.0  0.56250\n",
      "  2state  SJM-BL vs HMM-BL-KMeans        2.0  0.09375\n",
      "  3state             SJM-BL vs EW        3.0  0.15625\n",
      "  3state             SJM-BL vs IV        3.0  0.15625\n",
      "  3state            SJM-BL vs MVO        5.0  0.31250\n",
      "  3state SJM-BL vs HMM-BL-Default        6.0  0.43750\n",
      "  3state  SJM-BL vs HMM-BL-KMeans        0.0  0.03125\n",
      "\n",
      "==== Average Performance Metrics (across runs) ====\n",
      "\n",
      "--- 1STATE ---\n",
      "                Annualized Return  Cumulative Return  Volatility  Downside Deviation  Max Drawdown  Sharpe Ratio  Sortino Ratio  Calmar Ratio  Turnover Rate\n",
      "Strategy                                                                                                                                                    \n",
      "EW                       0.153223           0.352544    0.076298            0.043939     -0.062352      2.007127       3.499152      2.971863       0.000000\n",
      "IV                       0.153549           0.353496    0.076257            0.043907     -0.062417      2.012692       3.509015      2.964972       0.000000\n",
      "MVO                      0.138529           0.312327    0.092952            0.054094     -0.076410      1.482954       2.574568      1.978832       0.000000\n",
      "HMM-BL-Default           0.145649           0.332177    0.079892            0.046318     -0.064343      1.825331       3.143841      2.653694       0.001621\n",
      "HMM-BL-KMeans           -0.065693          -0.130027    0.103355            0.062285     -0.223992     -0.640470      -1.065773     -0.271372       1.223804\n",
      "SJM-BL                   0.166992           0.387880    0.090465            0.052081     -0.074520      1.869997       3.275258      2.854138       0.027791\n",
      "\n",
      "--- 2STATE ---\n",
      "                Annualized Return  Cumulative Return  Volatility  Downside Deviation  Max Drawdown  Sharpe Ratio  Sortino Ratio  Calmar Ratio  Turnover Rate\n",
      "Strategy                                                                                                                                                    \n",
      "EW                       0.083286           0.185587    0.077348            0.048207     -0.101708      1.094725       1.800399      1.339450       0.000000\n",
      "IV                       0.088542           0.197562    0.075739            0.046613     -0.097105      1.186791       1.947731      1.402833       0.000000\n",
      "MVO                      0.065680           0.142650    0.091816            0.057521     -0.130690      0.761831       1.261600      0.833152       0.000000\n",
      "HMM-BL-Default           0.095771           0.217694    0.074694            0.045368     -0.087926      1.295267       2.155761      1.769306       0.015444\n",
      "HMM-BL-KMeans           -0.013283           0.004970    0.095308            0.062489     -0.193985      0.139503       0.373075      0.721970       0.530044\n",
      "SJM-BL                   0.101795           0.225627    0.091538            0.058003     -0.110938      1.153553       1.899356      1.615418       0.026168\n",
      "\n",
      "--- 3STATE ---\n",
      "                Annualized Return  Cumulative Return  Volatility  Downside Deviation  Max Drawdown  Sharpe Ratio  Sortino Ratio  Calmar Ratio  Turnover Rate\n",
      "Strategy                                                                                                                                                    \n",
      "EW                       0.074561           0.174842    0.074638            0.046474     -0.105239      1.165900       1.998863      1.676828       0.000000\n",
      "IV                       0.108203           0.246345    0.068931            0.041090     -0.062728      1.664498       2.880879      2.645044       0.000000\n",
      "MVO                      0.123277           0.297825    0.084018            0.053008     -0.105421      1.683648       2.865478      2.599322       0.000000\n",
      "HMM-BL-Default           0.153063           0.354301    0.066261            0.039034     -0.047723      2.337801       4.019655      3.891258       0.004031\n",
      "HMM-BL-KMeans           -0.084116          -0.129875    0.110987            0.075201     -0.255854     -0.612020      -0.787794      0.021695       0.961865\n",
      "SJM-BL                   0.161988           0.379282    0.075773            0.045785     -0.056058      2.142487       3.580283      3.107477       0.016549\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Centralized parameter configuration\n",
    "    config = {\n",
    "        \"n_simulations\": 6,\n",
    "        \"T_sim\": 2500,\n",
    "        \"risk_free_rate\": 0.02 / 252,\n",
    "        \"transaction_cost\": 0.0007,\n",
    "        \"bl_tau\": 0.05,\n",
    "        \"lam_sjm\": 90,\n",
    "    }\n",
    "\n",
    "    # Run the Monte Carlo study using all config values\n",
    "    sharpe_data, all_metrics, all_runs, df_wilcoxon = run_monte_carlo_study(\n",
    "        n_runs=config[\"n_simulations\"],\n",
    "        T_sim=config[\"T_sim\"],\n",
    "        lam_sjm=config[\"lam_sjm\"],\n",
    "        risk_free_rate=config[\"risk_free_rate\"],\n",
    "        transaction_cost=config[\"transaction_cost\"],\n",
    "        bl_tau=config[\"bl_tau\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
