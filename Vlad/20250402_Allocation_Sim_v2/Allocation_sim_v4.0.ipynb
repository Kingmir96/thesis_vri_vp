{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wilcoxon\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# Hidden Markov Model utilities\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# PyPortfolioOpt\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models, expected_returns\n",
    "from pypfopt.black_litterman import BlackLittermanModel\n",
    "\n",
    "# Sparse Jump Model utilities\n",
    "from jumpmodels.sparse_jump import SparseJumpModel\n",
    "from jumpmodels.preprocess import StandardScalerPD, DataClipperStd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSETS = [\"Value\", \"Growth\", \"LowVol\", \"Size\", \"Momentum\", \"Quality\"]\n",
    "N_ASSETS = len(ASSETS)\n",
    "\n",
    "# For demonstration, these are the base parameters for the simulation only:\n",
    "SIM_MEAN_1STATE = 0.000461\n",
    "SIM_SIG_1STATE  = 0.008388\n",
    "\n",
    "RISK_FREE_RATE = 0.0\n",
    "TRANSACTION_COST = 0.0005  \n",
    "BL_TAU = 0.1  # Black-Litterman parameter\n",
    "\n",
    "def simulate_1state_data(num_days, seed=None):\n",
    "    np_rng = np.random.default_rng(seed)\n",
    "    mu = SIM_MEAN_1STATE\n",
    "    sig = SIM_SIG_1STATE\n",
    "\n",
    "    corr = np.full((N_ASSETS, N_ASSETS), 0.185)\n",
    "    np.fill_diagonal(corr, 1.0)\n",
    "    cov = np.outer(np.full(N_ASSETS, sig), np.full(N_ASSETS, sig)) * corr\n",
    "\n",
    "    rets = np_rng.multivariate_normal(mean=np.full(N_ASSETS, mu), \n",
    "                                      cov=cov, \n",
    "                                      size=num_days)\n",
    "    return pd.DataFrame(rets, columns=ASSETS)\n",
    "\n",
    "def simulate_2state_data(num_days, seed=None):\n",
    "    np_rng = np.random.default_rng(seed)\n",
    "    transmat = np.array([[0.9976, 0.0024],\n",
    "                         [0.0232, 0.9768]])\n",
    "    mu_dict  = {0: 0.0006,   1: -0.000881}\n",
    "    sig_dict = {0: 0.00757, 1: 0.0163}\n",
    "\n",
    "    base_corr = np.full((N_ASSETS, N_ASSETS), 0.185)\n",
    "    np.fill_diagonal(base_corr, 1.0)\n",
    "\n",
    "    all_states = np.zeros((num_days, N_ASSETS), dtype=int)\n",
    "    for i in range(N_ASSETS):\n",
    "        s = np.zeros(num_days, dtype=int)\n",
    "        s[0] = np_rng.integers(2)\n",
    "        for t in range(1, num_days):\n",
    "            s[t] = np_rng.choice(2, p=transmat[s[t - 1]])\n",
    "        all_states[:, i] = s\n",
    "\n",
    "    rets = np.zeros((num_days, N_ASSETS))\n",
    "    for t in range(num_days):\n",
    "        mu_vec  = np.zeros(N_ASSETS)\n",
    "        sig_vec = np.zeros(N_ASSETS)\n",
    "        for i in range(N_ASSETS):\n",
    "            curr_state = all_states[t, i]\n",
    "            mu_vec[i]  = mu_dict[curr_state]\n",
    "            sig_vec[i] = sig_dict[curr_state]\n",
    "        cov_t = np.outer(sig_vec, sig_vec) * base_corr\n",
    "        rets[t] = np_rng.multivariate_normal(mean=mu_vec, cov=cov_t)\n",
    "\n",
    "    return pd.DataFrame(rets, columns=ASSETS), all_states\n",
    "\n",
    "def simulate_3state_data(num_days, seed=None):\n",
    "    np_rng = np.random.default_rng(seed)\n",
    "    transmat = np.array([[0.9989, 0.0004, 0.0007],\n",
    "                         [0.0089, 0.9904, 0.0007],\n",
    "                         [0.0089, 0.0004, 0.9907]])\n",
    "    mu_list  = [0.0008, 0.0,     -0.003586]\n",
    "    sig_list = [0.0070, 0.0050,  0.01897]\n",
    "\n",
    "    base_corr = np.full((N_ASSETS, N_ASSETS), 0.185)\n",
    "    np.fill_diagonal(base_corr, 1.0)\n",
    "\n",
    "    all_states = np.zeros((num_days, N_ASSETS), dtype=int)\n",
    "    for i in range(N_ASSETS):\n",
    "        s = np.zeros(num_days, dtype=int)\n",
    "        s[0] = np_rng.integers(3)\n",
    "        for t in range(1, num_days):\n",
    "            s[t] = np_rng.choice(3, p=transmat[s[t - 1]])\n",
    "        all_states[:, i] = s\n",
    "\n",
    "    rets = np.zeros((num_days, N_ASSETS))\n",
    "    for t in range(num_days):\n",
    "        mu_vec  = np.zeros(N_ASSETS)\n",
    "        sig_vec = np.zeros(N_ASSETS)\n",
    "        for i in range(N_ASSETS):\n",
    "            st_i   = all_states[t, i]\n",
    "            mu_vec[i]  = mu_list[st_i]\n",
    "            sig_vec[i] = sig_list[st_i]\n",
    "        cov_t = np.outer(sig_vec, sig_vec) * base_corr\n",
    "        rets[t] = np_rng.multivariate_normal(mean=mu_vec, cov=cov_t)\n",
    "\n",
    "    return pd.DataFrame(rets, columns=ASSETS), all_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training Regime Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def run_mle(observations, n_components=2, init_type='default', seed=None):\n",
    "    model = GaussianHMM(n_components=n_components, covariance_type='diag',\n",
    "                        n_iter=100, random_state=seed)\n",
    "\n",
    "    if init_type == 'default':\n",
    "        model.startprob_ = np.array([1.0, 0.0])\n",
    "        model.transmat_  = np.array([[0.9, 0.1],\n",
    "                                     [0.1, 0.9]])\n",
    "        model.means_  = np.zeros((n_components, observations.shape[1]))\n",
    "        model.covars_ = np.full((n_components, observations.shape[1]), 1e-10)\n",
    "        model.init_params = ''\n",
    "    elif init_type == 'kmeans':\n",
    "        km = KMeans(n_clusters=n_components, n_init=10, random_state=seed)\n",
    "        labels = km.fit_predict(observations)\n",
    "        means, covars = [], []\n",
    "        for i in range(n_components):\n",
    "            obs_i = observations[labels == i]\n",
    "            means.append(np.mean(obs_i, axis=0))\n",
    "            covars.append(np.var(obs_i, axis=0) + 1e-10)\n",
    "        model.startprob_ = np.ones(n_components) / n_components\n",
    "        model.transmat_  = np.ones((n_components, n_components)) / n_components\n",
    "        model.means_     = np.array(means)\n",
    "        model.covars_    = np.array(covars)\n",
    "        model.init_params = ''\n",
    "\n",
    "    model.fit(observations)\n",
    "    pred_states = model.predict(observations)\n",
    "    return model, pred_states\n",
    "\n",
    "def run_mle_default(observations, seed=None):\n",
    "    return run_mle(observations, init_type='default', seed=seed)\n",
    "\n",
    "def run_mle_kmeans(observations, seed=None):\n",
    "    return run_mle(observations, init_type='kmeans', seed=seed)\n",
    "\n",
    "def train_hmm_single_asset_default(series, n_components=2, random_state=42):\n",
    "    X = series.values.reshape(-1, 1)\n",
    "    model, _ = run_mle_default(X, seed=random_state)\n",
    "    return model\n",
    "\n",
    "def train_hmm_single_asset_kmeans(series, n_components=2, random_state=42):\n",
    "    X = series.values.reshape(-1, 1)\n",
    "    model, _ = run_mle_kmeans(X, seed=random_state)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Feature selection and SJM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "def compute_sjm_features(factor_ser: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build strictly backward-looking features for a single factor 'factor_ser'.\n",
    "    Returns a DataFrame with 12 columns (EWMAs, RSI, Stoch, MACD, DownsideDev).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    factor_price = 100.0 * (1.0 + factor_ser).cumprod()\n",
    "\n",
    "    def ewma_return(returns, halflife):\n",
    "        return returns.ewm(halflife=halflife).mean()\n",
    "\n",
    "    def compute_rsi(price, window):\n",
    "        delta = price.diff()\n",
    "        gain  = delta.clip(lower=0)\n",
    "        loss  = -delta.clip(upper=0)\n",
    "        avg_gain = gain.rolling(window).mean()\n",
    "        avg_loss = loss.rolling(window).mean()\n",
    "        rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "        return 100.0 - (100.0 / (1.0 + rs))\n",
    "\n",
    "    def compute_stoch(price, window):\n",
    "        rolling_min = price.rolling(window).min()\n",
    "        rolling_max = price.rolling(window).max()\n",
    "        return 100.0 * (price - rolling_min) / (rolling_max - rolling_min)\n",
    "\n",
    "    def compute_macd(price, fast, slow):\n",
    "        ema_fast = price.ewm(halflife=fast).mean()\n",
    "        ema_slow = price.ewm(halflife=slow).mean()\n",
    "        return ema_fast - ema_slow\n",
    "\n",
    "    def compute_downside_dev_log(returns, window):\n",
    "        def _downside(subarray):\n",
    "            negatives = np.where(subarray < 0, subarray, 0.0)\n",
    "            return np.sqrt((negatives**2).mean())\n",
    "        dd = returns.rolling(window).apply(_downside, raw=True)\n",
    "        return np.log(dd.replace(0, np.nan))\n",
    "\n",
    "    feats = {}\n",
    "    for hl in [8, 21, 63]:\n",
    "        feats[f\"FactorRet_EWMA_{hl}\"] = ewma_return(factor_ser, hl)\n",
    "    for w in [8, 21, 63]:\n",
    "        feats[f\"RSI_{w}\"] = compute_rsi(factor_price, w)\n",
    "    for w in [8, 21, 63]:\n",
    "        feats[f\"Stoch%K_{w}\"] = compute_stoch(factor_price, w)\n",
    "\n",
    "    feats[\"MACD_8_21\"]   = compute_macd(factor_price, 8, 21)\n",
    "    feats[\"MACD_21_63\"]  = compute_macd(factor_price, 21, 63)\n",
    "    feats[\"DownsideDev_log_21\"] = compute_downside_dev_log(factor_ser, 21)\n",
    "    \n",
    "    return pd.DataFrame(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SJM\n",
    "def train_sjm_single_asset(series, n_components=2, max_feats=12, lam=90, random_state=42):\n",
    "    \"\"\"\n",
    "    Train SJM on one asset, using the backward-looking features from above.\n",
    "    \"\"\"\n",
    "    feats_df = compute_sjm_features(series)\n",
    "    feats_df = feats_df.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    clipper = DataClipperStd(mul=3.0)\n",
    "    scaler  = StandardScalerPD()\n",
    "\n",
    "    X_clipped = clipper.fit_transform(feats_df)\n",
    "    X_scaled  = scaler.fit_transform(X_clipped)\n",
    "    X_arr = X_scaled.values\n",
    "\n",
    "    sjm = SparseJumpModel(\n",
    "        n_components=n_components,\n",
    "        max_feats=max_feats,\n",
    "        jump_penalty=lam,\n",
    "        cont=False,\n",
    "        max_iter=20,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    sjm.fit(X_arr)\n",
    "\n",
    "    return sjm, clipper, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Allocation simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Backtest a static portfolio with single allocaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def backtest_portfolio(returns, weights):\n",
    "    \"\"\"\n",
    "    Backtest a static portfolio with a single allocation across the entire test period.\n",
    "    Includes initial transaction cost.\n",
    "    \"\"\"\n",
    "    T = len(returns)\n",
    "    portfolio_vals = np.zeros(T)\n",
    "    cost_init = np.sum(np.abs(weights)) * TRANSACTION_COST\n",
    "    portfolio_vals[0] = 1.0 - cost_init\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        ret_t = returns.iloc[t].values\n",
    "        portfolio_vals[t + 1] = portfolio_vals[t] * (1.0 + np.dot(weights, ret_t))\n",
    "\n",
    "    return portfolio_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 Performance Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metric\n",
    "def compute_performance_metrics(portfolio_vals, weight_history=None, annual_factor=250):\n",
    "    \"\"\"\n",
    "    Calculate performance stats on the final portfolio_vals series.\n",
    "    \"\"\"\n",
    "    pv = np.asarray(portfolio_vals)\n",
    "    rets = np.diff(pv) / pv[:-1]\n",
    "\n",
    "    ann_ret = rets.mean() * annual_factor\n",
    "    cum_ret = pv[-1]/pv[0] - 1\n",
    "    ann_vol = rets.std() * np.sqrt(annual_factor)\n",
    "\n",
    "    negative_rets = rets[rets < 0]\n",
    "    ddev = negative_rets.std() * np.sqrt(annual_factor) if len(negative_rets) > 0 else 0.0\n",
    "    max_dd = (pv / np.maximum.accumulate(pv) - 1).min()\n",
    "\n",
    "    sharpe = ann_ret/(ann_vol + 1e-12)\n",
    "    sortino = ann_ret/ddev if ddev > 1e-12 else np.nan\n",
    "    calmar  = ann_ret/abs(max_dd) if max_dd < 0 else np.nan\n",
    "\n",
    "    if weight_history is not None and len(weight_history) > 1:\n",
    "        turnovers = []\n",
    "        for t in range(1, len(weight_history)):\n",
    "            turnovers.append(np.sum(np.abs(weight_history[t] - weight_history[t-1])))\n",
    "        avg_turnover = np.mean(turnovers)\n",
    "    else:\n",
    "        avg_turnover = 0.0\n",
    "\n",
    "    return {\n",
    "        \"Annualized Return\": ann_ret,\n",
    "        \"Cumulative Return\": cum_ret,\n",
    "        \"Volatility\": ann_vol,\n",
    "        \"Downside Deviation\": ddev,\n",
    "        \"Max Drawdown\": max_dd,\n",
    "        \"Sharpe Ratio\": sharpe,\n",
    "        \"Sortino Ratio\": sortino,\n",
    "        \"Calmar Ratio\": calmar,\n",
    "        \"Turnover Rate\": avg_turnover,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Helper Function: get per-regime means & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regime_means_stds_single_asset(asset_series, regime_assignments):\n",
    "    \"\"\"\n",
    "    Returns two dicts:\n",
    "      means_dict = {state: mean_return_in_that_state}\n",
    "      stds_dict  = {state: std_return_in_that_state}\n",
    "    \"\"\"\n",
    "    unique_states = np.unique(regime_assignments)\n",
    "    regime_means = {}\n",
    "    regime_stds  = {}\n",
    "    for s in unique_states:\n",
    "        data_in_s = asset_series[regime_assignments == s]\n",
    "        if len(data_in_s) > 0:\n",
    "            regime_means[s] = data_in_s.mean()\n",
    "            regime_stds[s]  = data_in_s.std()\n",
    "        else:\n",
    "            # fallback if somehow empty\n",
    "            regime_means[s] = asset_series.mean()\n",
    "            regime_stds[s]  = asset_series.std()\n",
    "    return regime_means, regime_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Equal Unconditional Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def build_equal_unconditional_prior(df_train):\n",
    "    \"\"\"\n",
    "    Build an 'equal unconditional prior' for BL:\n",
    "      - One scalar unconditional return (average of all returns in df_train).\n",
    "      - One scalar stdev (average stdev across assets).\n",
    "      - One scalar correlation (average correlation).\n",
    "    => Covariance has stdev^2 on diagonal and stdev^2 * avg_corr off-diagonal.\n",
    "    => pi (prior) is a vector of identical means.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    overall_mean = df_train.stack().mean()            # scalar\n",
    "    avg_stdev    = df_train.std(axis=0).mean()        # scalar\n",
    "    corr_matrix  = df_train.corr()\n",
    "    avg_corr     = corr_matrix.stack().mean()         # scalar\n",
    "\n",
    "    n_assets = df_train.shape[1]\n",
    "    uniform_corr = np.full((n_assets, n_assets), avg_corr)\n",
    "    np.fill_diagonal(uniform_corr, 1.0)\n",
    "\n",
    "    cov_flat = (avg_stdev**2) * uniform_corr\n",
    "\n",
    "    assets = df_train.columns\n",
    "    pi_series = pd.Series(np.full(n_assets, overall_mean), index=assets)\n",
    "    cov_df    = pd.DataFrame(cov_flat, index=assets, columns=assets)\n",
    "    return pi_series, cov_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.0 Regime-Based BL with the 'Equal Unconditional Prior'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def regime_based_bl_backtest_flatprior(\n",
    "    df_test, \n",
    "    states_test,\n",
    "    regime_means_list,  # list of dict {state: mean}\n",
    "    flat_pi,            # from build_equal_unconditional_prior\n",
    "    flat_cov,           # from build_equal_unconditional_prior\n",
    "    train_means_per_asset\n",
    "):\n",
    "    \"\"\"\n",
    "    Daily rebalancing using a 'flat' prior (equal unconditional mean, volatility, corr).\n",
    "    The regime means are the 'views'. We do absolute views in Black-Litterman.\n",
    "    \"\"\"\n",
    "    T_test = len(df_test)\n",
    "    n_assets = len(df_test.columns)\n",
    "    assets = df_test.columns\n",
    "\n",
    "    portfolio_vals = np.zeros(T_test)\n",
    "    portfolio_vals[0] = 1.0\n",
    "\n",
    "    weight_history = np.zeros((T_test, n_assets))\n",
    "    w_prev = np.ones(n_assets) / n_assets  # start equal weighted\n",
    "    weight_history[0] = w_prev\n",
    "\n",
    "    for t in range(T_test - 1):\n",
    "        # 1) Construct daily 'absolute_views' from the regime\n",
    "        view_vector = np.zeros(n_assets)\n",
    "        for i in range(n_assets):\n",
    "            current_regime = states_test[t, i]\n",
    "            # fallback if not found\n",
    "            mean_i = regime_means_list[i].get(current_regime, train_means_per_asset[i])\n",
    "            view_vector[i] = mean_i\n",
    "        day_views = dict(zip(assets, view_vector))\n",
    "\n",
    "        # 2) Build BL with flat prior\n",
    "        bl = BlackLittermanModel(\n",
    "            cov_matrix    = flat_cov,\n",
    "            pi            = flat_pi,\n",
    "            absolute_views= day_views,\n",
    "            tau           = BL_TAU,\n",
    "            risk_aversion = 1.0\n",
    "        )\n",
    "        bl_rets = bl.bl_returns()\n",
    "        bl_cov  = bl.bl_cov()\n",
    "\n",
    "        # 3) Solve for weights\n",
    "        ef = EfficientFrontier(bl_rets, bl_cov, weight_bounds=(0,1), solver=\"SCS\")\n",
    "        try:\n",
    "            w_dict = ef.max_sharpe(risk_free_rate=RISK_FREE_RATE)\n",
    "        except:\n",
    "            w_dict = ef.min_volatility()\n",
    "        w_array = np.array([w_dict[a] for a in assets])\n",
    "\n",
    "        # 4) Transaction cost & portfolio update\n",
    "        ret_t = df_test.iloc[t].values\n",
    "        gross_growth = portfolio_vals[t] * (1.0 + np.dot(w_prev, ret_t))\n",
    "        traded_fraction = np.sum(np.abs(w_array - w_prev))\n",
    "        cost = gross_growth * traded_fraction * TRANSACTION_COST\n",
    "\n",
    "        portfolio_vals[t + 1] = gross_growth - cost\n",
    "        weight_history[t + 1] = w_array\n",
    "        w_prev = w_array\n",
    "\n",
    "    return portfolio_vals, weight_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Wrapper to run all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy dedinition\n",
    "def equal_weight_allocation(n_assets):\n",
    "    return np.ones(n_assets)/n_assets\n",
    "\n",
    "def inverse_vol_weights(returns):\n",
    "    stds = returns.std(axis=0).values + 1e-12\n",
    "    w = 1.0/stds\n",
    "    return w / w.sum()\n",
    "\n",
    "def static_mvo_allocation(returns):\n",
    "    \"\"\"\n",
    "    Static mean-variance optimization using historical mean and sample covariance.\n",
    "    A small ridge is added to improve numerical stability.\n",
    "    If the SCS solver fails, fall back to the ECOS solver.\n",
    "    \"\"\"\n",
    "    mu = expected_returns.mean_historical_return(returns, frequency=250)\n",
    "    raw_cov = risk_models.sample_cov(returns)\n",
    "    ridge_lambda = 1e-5\n",
    "    cov = raw_cov + np.eye(len(raw_cov)) * ridge_lambda\n",
    "    try:\n",
    "        ef = EfficientFrontier(mu, cov, weight_bounds=(0,1), solver=\"SCS\")\n",
    "        ef_weights = ef.max_sharpe(risk_free_rate=RISK_FREE_RATE)\n",
    "    except Exception as e:\n",
    "        print(\"SCS solver in static MVO failed, switching to ECOS:\", e)\n",
    "        ef = EfficientFrontier(mu, cov, weight_bounds=(0,1), solver=\"ECOS\")\n",
    "        ef_weights = ef.max_sharpe(risk_free_rate=RISK_FREE_RATE)\n",
    "    return ef.clean_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Run\n",
    "def run_allocation(df, lam_sjm=90):\n",
    "    \"\"\"\n",
    "    Trains HMM & SJM, runs:\n",
    "     1) Equal Weight\n",
    "     2) Inverse Vol\n",
    "     3) Static MVO\n",
    "     4) HMM-BL (flat prior)\n",
    "     5) HMM-BL-KMeans (flat prior)\n",
    "     6) SJM-BL (flat prior)\n",
    "    \"\"\"\n",
    "    split_idx = int(len(df)*0.8)\n",
    "    df_train = df.iloc[:split_idx]\n",
    "    df_test  = df.iloc[split_idx:]\n",
    "\n",
    "    # 1) Train per-asset models\n",
    "    hmm_models_default = []\n",
    "    hmm_models_kmeans  = []\n",
    "    sjm_models         = []\n",
    "    sjm_clippers       = []\n",
    "    sjm_scalers        = []\n",
    "\n",
    "    hmm_states_default_train = np.zeros((split_idx, N_ASSETS), dtype=int)\n",
    "    hmm_states_kmeans_train  = np.zeros((split_idx, N_ASSETS), dtype=int)\n",
    "    sjm_states_train         = np.zeros((split_idx, N_ASSETS), dtype=int)\n",
    "\n",
    "    for i, asset in enumerate(ASSETS):\n",
    "        series_train = df_train[asset]\n",
    "\n",
    "        # HMM default\n",
    "        hmm_d = train_hmm_single_asset_default(series_train)\n",
    "        st_def = hmm_d.predict(series_train.values.reshape(-1,1))\n",
    "        hmm_models_default.append(hmm_d)\n",
    "        hmm_states_default_train[:, i] = st_def\n",
    "\n",
    "        # HMM kmeans\n",
    "        hmm_k = train_hmm_single_asset_kmeans(series_train)\n",
    "        st_km = hmm_k.predict(series_train.values.reshape(-1,1))\n",
    "        hmm_models_kmeans.append(hmm_k)\n",
    "        hmm_states_kmeans_train[:, i] = st_km\n",
    "\n",
    "        # SJM\n",
    "        sjm_mod, sjm_clip, sjm_scale = train_sjm_single_asset(\n",
    "            series_train, n_components=2, max_feats=12, lam=lam_sjm\n",
    "        )\n",
    "        feats_train = compute_sjm_features(series_train)\n",
    "        feats_train = feats_train.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        X_train_clip = sjm_clip.transform(feats_train)\n",
    "        X_train_scl  = sjm_scale.transform(X_train_clip)\n",
    "        st_sjm = sjm_mod.predict(X_train_scl)\n",
    "\n",
    "        sjm_models.append(sjm_mod)\n",
    "        sjm_clippers.append(sjm_clip)\n",
    "        sjm_scalers.append(sjm_scale)\n",
    "        sjm_states_train[:, i] = st_sjm\n",
    "\n",
    "    # 2) In-sample regime means\n",
    "    hmm_regime_means_default = []\n",
    "    hmm_regime_means_kmeans  = []\n",
    "    sjm_regime_means         = []\n",
    "    train_means_per_asset    = []\n",
    "    for i in range(N_ASSETS):\n",
    "        asset_train = df_train.iloc[:, i]\n",
    "        train_means_per_asset.append(asset_train.mean())\n",
    "\n",
    "        m_def, _ = get_regime_means_stds_single_asset(asset_train, hmm_states_default_train[:, i])\n",
    "        hmm_regime_means_default.append(m_def)\n",
    "\n",
    "        m_km, _ = get_regime_means_stds_single_asset(asset_train, hmm_states_kmeans_train[:, i])\n",
    "        hmm_regime_means_kmeans.append(m_km)\n",
    "\n",
    "        m_sjm, _ = get_regime_means_stds_single_asset(asset_train, sjm_states_train[:, i])\n",
    "        sjm_regime_means.append(m_sjm)\n",
    "\n",
    "    # 3) Predict states on test\n",
    "    T_test = len(df_test)\n",
    "    hmm_states_default_test = np.zeros((T_test, N_ASSETS), dtype=int)\n",
    "    hmm_states_kmeans_test  = np.zeros((T_test, N_ASSETS), dtype=int)\n",
    "    sjm_states_test         = np.zeros((T_test, N_ASSETS), dtype=int)\n",
    "    for i, asset in enumerate(ASSETS):\n",
    "        arr_test = df_test[asset].values.reshape(-1,1)\n",
    "        hmm_states_default_test[:, i] = hmm_models_default[i].predict(arr_test)\n",
    "        hmm_states_kmeans_test[:, i]  = hmm_models_kmeans[i].predict(arr_test)\n",
    "\n",
    "        feats_test = compute_sjm_features(df_test[asset])\n",
    "        feats_test = feats_test.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        X_test_clip = sjm_clippers[i].transform(feats_test)\n",
    "        X_test_scl  = sjm_scalers[i].transform(X_test_clip)\n",
    "        sjm_states_test[:, i] = sjm_models[i].predict(X_test_scl)\n",
    "\n",
    "    # 4) Build the 'flat' unconditional prior\n",
    "    flat_pi, flat_cov = build_equal_unconditional_prior(df_train)\n",
    "\n",
    "    # 5) Evaluate strategies\n",
    "\n",
    "    # (A) Equal Weight\n",
    "    w_ew = equal_weight_allocation(N_ASSETS)\n",
    "    pv_ew = backtest_portfolio(df_test, w_ew)\n",
    "    w_hist_ew = np.tile(w_ew, (T_test, 1))\n",
    "\n",
    "    # (B) Inverse Vol\n",
    "    w_iv = inverse_vol_weights(df_test)\n",
    "    pv_iv = backtest_portfolio(df_test, w_iv)\n",
    "    w_hist_iv = np.tile(w_iv, (T_test, 1))\n",
    "\n",
    "    # (C) Static MVO\n",
    "    w_mvo_dict = static_mvo_allocation(df_train)\n",
    "    w_mvo_arr = np.array([w_mvo_dict[a] for a in ASSETS])\n",
    "    pv_mvo = backtest_portfolio(df_test, w_mvo_arr)\n",
    "    w_hist_mvo = np.tile(w_mvo_arr, (T_test, 1))\n",
    "\n",
    "    # (D) HMM-BL (Default)\n",
    "    pv_hmmbl_def, w_hmmbl_def = regime_based_bl_backtest_flatprior(\n",
    "        df_test,\n",
    "        hmm_states_default_test,\n",
    "        hmm_regime_means_default,\n",
    "        flat_pi,\n",
    "        flat_cov,\n",
    "        train_means_per_asset\n",
    "    )\n",
    "\n",
    "    # (E) HMM-BL (KMeans)\n",
    "    pv_hmmbl_km, w_hmmbl_km = regime_based_bl_backtest_flatprior(\n",
    "        df_test,\n",
    "        hmm_states_kmeans_test,\n",
    "        hmm_regime_means_kmeans,\n",
    "        flat_pi,\n",
    "        flat_cov,\n",
    "        train_means_per_asset\n",
    "    )\n",
    "\n",
    "    # (F) SJM-BL\n",
    "    pv_sjmbl, w_sjmbl = regime_based_bl_backtest_flatprior(\n",
    "        df_test,\n",
    "        sjm_states_test,\n",
    "        sjm_regime_means,\n",
    "        flat_pi,\n",
    "        flat_cov,\n",
    "        train_means_per_asset\n",
    "    )\n",
    "\n",
    "    perf = {\n",
    "        \"EW\": compute_performance_metrics(pv_ew, w_hist_ew),\n",
    "        \"IV\": compute_performance_metrics(pv_iv, w_hist_iv),\n",
    "        \"MVO\": compute_performance_metrics(pv_mvo, w_hist_mvo),\n",
    "        \"HMM-BL-Default\": compute_performance_metrics(pv_hmmbl_def, w_hmmbl_def),\n",
    "        \"HMM-BL-KMeans\":  compute_performance_metrics(pv_hmmbl_km, w_hmmbl_km),\n",
    "        \"SJM-BL\":         compute_performance_metrics(pv_sjmbl, w_sjmbl)\n",
    "    }\n",
    "\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. FUll scenario 1-state, 2-state, 3-state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario_123(T_sim=1000, seed1=None, seed2=None, seed3=None):\n",
    "    \"\"\"\n",
    "    Simulate & run 1-state, 2-state, 3-state data sets.\n",
    "    \"\"\"\n",
    "    df1_full = simulate_1state_data(T_sim, seed=seed1)\n",
    "    perf_1 = run_allocation(df1_full)\n",
    "\n",
    "    df2_full, _ = simulate_2state_data(T_sim, seed=seed2)\n",
    "    perf_2 = run_allocation(df2_full)\n",
    "\n",
    "    df3_full, _ = simulate_3state_data(T_sim, seed=seed3)\n",
    "    perf_3 = run_allocation(df3_full)\n",
    "\n",
    "    return {\n",
    "        \"1state\": perf_1,\n",
    "        \"2state\": perf_2,\n",
    "        \"3state\": perf_3\n",
    "    }\n",
    "\n",
    "def single_monte_carlo_run(run_id, T_sim=1000):\n",
    "    print(f\"Running simulation {run_id}...\")\n",
    "    seed_for_1state = run_id * 1000 + 11\n",
    "    seed_for_2state = run_id * 1000 + 22\n",
    "    seed_for_3state = run_id * 1000 + 33\n",
    "\n",
    "    results = run_scenario_123(\n",
    "        T_sim=T_sim,\n",
    "        seed1=seed_for_1state,\n",
    "        seed2=seed_for_2state,\n",
    "        seed3=seed_for_3state\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def run_monte_carlo_study(n_runs=10, T_sim=1000):\n",
    "    \"\"\"\n",
    "    Runs multiple replications in parallel. Then does Wilcoxon test on Sharpe Ratios.\n",
    "    \"\"\"\n",
    "    n_cores = multiprocessing.cpu_count()\n",
    "    print(f\"detected {n_cores} cores\")\n",
    "\n",
    "    all_results = Parallel(n_jobs=n_cores)(\n",
    "        delayed(single_monte_carlo_run)(i+1, T_sim) for i in range(n_runs)\n",
    "    )\n",
    "\n",
    "    # Strategies\n",
    "    strategies = [\"EW\", \"IV\", \"MVO\", \"HMM-BL-Default\", \"HMM-BL-KMeans\", \"SJM-BL\"]\n",
    "    scenarios  = [\"1state\", \"2state\", \"3state\"]\n",
    "\n",
    "    # Sharpe data for Wilcoxon\n",
    "    sharpe_data = {sc: {st: [] for st in strategies} for sc in scenarios}\n",
    "    all_metrics = {sc: {} for sc in scenarios}\n",
    "    for sc in scenarios:\n",
    "        all_metrics[sc] = {}\n",
    "        for st in strategies:\n",
    "            all_metrics[sc][st] = {\n",
    "                \"Annualized Return\": [],\n",
    "                \"Cumulative Return\": [],\n",
    "                \"Volatility\": [],\n",
    "                \"Downside Deviation\": [],\n",
    "                \"Max Drawdown\": [],\n",
    "                \"Sharpe Ratio\": [],\n",
    "                \"Sortino Ratio\": [],\n",
    "                \"Calmar Ratio\": [],\n",
    "                \"Turnover Rate\": [],\n",
    "            }\n",
    "\n",
    "    # Collect distribution of metrics\n",
    "    for run_res in all_results:\n",
    "        for sc in scenarios:\n",
    "            for st in strategies:\n",
    "                metrics_dict = run_res[sc][st]\n",
    "                sharpe_data[sc][st].append(metrics_dict[\"Sharpe Ratio\"])\n",
    "                for mkey in all_metrics[sc][st]:\n",
    "                    all_metrics[sc][st][mkey].append(metrics_dict[mkey])\n",
    "\n",
    "    # Wilcoxon test: SJM-BL vs others (Sharpe)\n",
    "    print(\"\\n==== Wilcoxon Tests (SJM-BL vs. others) ====\")\n",
    "    wilcoxon_rows = []\n",
    "    for sc in scenarios:\n",
    "        sjm_sharpes = sharpe_data[sc][\"SJM-BL\"]\n",
    "        for st in strategies:\n",
    "            if st == \"SJM-BL\":\n",
    "                continue\n",
    "            other_sharpes = sharpe_data[sc][st]\n",
    "            try:\n",
    "                stat, pval = wilcoxon(sjm_sharpes, other_sharpes, alternative='two-sided')\n",
    "            except ValueError:\n",
    "                stat, pval = np.nan, np.nan\n",
    "            print(f\"{sc} | SJM-BL vs {st}: stat={stat:.4f}, p={pval:.4g}\")\n",
    "            wilcoxon_rows.append({\n",
    "                \"Scenario\": sc,\n",
    "                \"Comparison\": f\"SJM-BL vs {st}\",\n",
    "                \"Statistic\": stat,\n",
    "                \"p-value\": pval\n",
    "            })\n",
    "\n",
    "    df_wilcoxon = pd.DataFrame(wilcoxon_rows)\n",
    "    print(\"\\nWilcoxon Results Table:\")\n",
    "    print(df_wilcoxon.to_string(index=False))\n",
    "\n",
    "    # Print average metrics\n",
    "    print(\"\\n==== Average Performance Metrics (across runs) ====\")\n",
    "    for sc in scenarios:\n",
    "        rows = []\n",
    "        for st in strategies:\n",
    "            metric_means = {}\n",
    "            for mkey, vals in all_metrics[sc][st].items():\n",
    "                metric_means[mkey] = np.mean(vals)\n",
    "            row = {\"Strategy\": st}\n",
    "            row.update(metric_means)\n",
    "            rows.append(row)\n",
    "        df_avg = pd.DataFrame(rows)\n",
    "        df_avg.set_index(\"Strategy\", inplace=True)\n",
    "        print(f\"\\n--- {sc.upper()} ---\")\n",
    "        print(df_avg.to_string())\n",
    "\n",
    "    return sharpe_data, all_metrics, all_results, df_wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Exectution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected 8 cores\n",
      "Running simulation 4...\n",
      "Running simulation 3...\n",
      "Running simulation 2...\n",
      "Running simulation 8...\n",
      "Running simulation 6...\n",
      "Running simulation 7...\n",
      "Running simulation 5...\n",
      "Running simulation 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: 13399.97468682194 is not greater than 13400.026712611634. Delta is -0.05202578969328897\n",
      "Model is not converging.  Current: 13430.843406489204 is not greater than 13430.876458913983. Delta is -0.033052424778361456\n",
      "Model is not converging.  Current: 13417.123647420682 is not greater than 13417.135908083997. Delta is -0.012260663315828424\n",
      "Model is not converging.  Current: 13461.444512960772 is not greater than 13461.462574048224. Delta is -0.018061087452224456\n",
      "Model is not converging.  Current: 13477.861014403064 is not greater than 13477.897984230327. Delta is -0.03696982726251008\n",
      "Model is not converging.  Current: 13384.939811275972 is not greater than 13384.963567917232. Delta is -0.023756641259751632\n",
      "Model is not converging.  Current: 13458.44335717629 is not greater than 13458.466881097735. Delta is -0.02352392144530313\n",
      "Model is not converging.  Current: 13447.338113765592 is not greater than 13447.353301179308. Delta is -0.015187413715466391\n",
      "Model is not converging.  Current: 13462.898706862929 is not greater than 13462.93507963494. Delta is -0.036372772012327914\n",
      "Model is not converging.  Current: 13384.283015944642 is not greater than 13384.291657760492. Delta is -0.008641815849841805\n",
      "Model is not converging.  Current: 13421.02177870159 is not greater than 13421.03472617778. Delta is -0.012947476190674934\n",
      "Model is not converging.  Current: 13375.547607300168 is not greater than 13375.567555383988. Delta is -0.019948083820054308\n",
      "Model is not converging.  Current: 13480.39719515895 is not greater than 13480.401366854374. Delta is -0.004171695423792698\n",
      "Model is not converging.  Current: 13416.502634233335 is not greater than 13416.580299258192. Delta is -0.07766502485719684\n",
      "Model is not converging.  Current: 13451.588503478912 is not greater than 13451.590400511674. Delta is -0.0018970327619172167\n",
      "Model is not converging.  Current: 13492.680395457206 is not greater than 13492.753342455084. Delta is -0.07294699787780701\n",
      "Model is not converging.  Current: 13428.905073388998 is not greater than 13428.917221144113. Delta is -0.01214775511471089\n",
      "Model is not converging.  Current: 13482.359134842107 is not greater than 13482.367062601059. Delta is -0.007927758952064323\n",
      "Model is not converging.  Current: 13430.970806585665 is not greater than 13431.03993357022. Delta is -0.0691269845556235\n",
      "Model is not converging.  Current: 13467.850384575173 is not greater than 13467.974295631035. Delta is -0.123911055861754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Model is not converging.  Current: 13448.95435023117 is not greater than 13448.955919831802. Delta is -0.0015696006321377354\n",
      "Model is not converging.  Current: 13476.085714253271 is not greater than 13476.164444167523. Delta is -0.07872991425210785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LDL factorization when computing the nonzero elements. The problem seems to be non-convex.\n",
      "factor_status: 0, num_vars: 7\n",
      "Error in LDL initial factorization.\n",
      "ERROR: init_lin_sys_work failure\n",
      "SCS solver in static MVO failed, switching to ECOS: ScsWork allocation error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/cvxpy/problems/problem.py:1504: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n",
      "Model is not converging.  Current: 13475.803503442388 is not greater than 13475.807757561965. Delta is -0.004254119576216908\n",
      "Model is not converging.  Current: 13475.802548561913 is not greater than 13475.804507009967. Delta is -0.0019584480542107485\n",
      "Model is not converging.  Current: 13519.865165012987 is not greater than 13519.95135763685. Delta is -0.08619262386309856\n",
      "Model is not converging.  Current: 13392.537879476446 is not greater than 13392.62322514505. Delta is -0.08534566860362247\n",
      "Model is not converging.  Current: 13392.563560121065 is not greater than 13392.637893202103. Delta is -0.07433308103827585\n",
      "Model is not converging.  Current: 13448.980465230197 is not greater than 13449.056881712593. Delta is -0.07641648239587084\n",
      "Model is not converging.  Current: 13448.071973352226 is not greater than 13448.135226222103. Delta is -0.06325286987703294\n",
      "Model is not converging.  Current: 13272.79084790031 is not greater than 13272.799533903004. Delta is -0.008686002693139017\n",
      "Model is not converging.  Current: 13516.67396583896 is not greater than 13516.680757591486. Delta is -0.006791752526623895\n",
      "Model is not converging.  Current: 13556.557441620107 is not greater than 13556.55910009154. Delta is -0.0016584714321652427\n",
      "Model is not converging.  Current: 13556.552089422566 is not greater than 13556.556328213921. Delta is -0.004238791354509885\n",
      "Model is not converging.  Current: 13322.759857633637 is not greater than 13322.791455116407. Delta is -0.031597482769939234\n",
      "Model is not converging.  Current: 13322.75963222329 is not greater than 13322.787329813167. Delta is -0.02769758987778914\n",
      "Model is not converging.  Current: 13584.595659604283 is not greater than 13584.689496994924. Delta is -0.09383739064105612\n",
      "Model is not converging.  Current: 13584.609239779866 is not greater than 13584.691938309361. Delta is -0.08269852949524648\n",
      "Model is not converging.  Current: 13531.08704238805 is not greater than 13531.122596417064. Delta is -0.03555402901474736\n",
      "Model is not converging.  Current: 13531.070328997173 is not greater than 13531.093359238008. Delta is -0.023030240834486904\n",
      "Model is not converging.  Current: 13442.79226397249 is not greater than 13442.81669565347. Delta is -0.024431680980342207\n",
      "Model is not converging.  Current: 13572.441225338818 is not greater than 13572.454665262112. Delta is -0.013439923293844913\n",
      "Model is not converging.  Current: 13434.800814051017 is not greater than 13434.803674697487. Delta is -0.0028606464693439193\n",
      "Model is not converging.  Current: 13265.597026257688 is not greater than 13265.659958279835. Delta is -0.06293202214692428\n",
      "Model is not converging.  Current: 13262.408930947933 is not greater than 13262.465672323062. Delta is -0.056741375128694926\n",
      "Model is not converging.  Current: 13702.562410045384 is not greater than 13702.632431568874. Delta is -0.07002152349014068\n",
      "Model is not converging.  Current: 13702.546851581392 is not greater than 13702.598364801435. Delta is -0.05151322004348913\n",
      "Model is not converging.  Current: 13303.3115747099 is not greater than 13303.312956495032. Delta is -0.001381785132252844\n",
      "Model is not converging.  Current: 13303.311499094403 is not greater than 13303.312078515448. Delta is -0.0005794210446765646\n",
      "Model is not converging.  Current: 13418.443206536373 is not greater than 13418.601909647203. Delta is -0.1587031108301744\n",
      "Model is not converging.  Current: 13418.385024807616 is not greater than 13418.457903843384. Delta is -0.07287903576798271\n",
      "Model is not converging.  Current: 13611.45113813625 is not greater than 13611.513514410797. Delta is -0.06237627454720496\n",
      "Model is not converging.  Current: 13611.457344525026 is not greater than 13611.5005757294. Delta is -0.043231204374023946\n",
      "Model is not converging.  Current: 13534.898041609153 is not greater than 13534.937700939676. Delta is -0.039659330523136305\n",
      "Model is not converging.  Current: 13534.89585601338 is not greater than 13534.927795598669. Delta is -0.031939585289364913\n",
      "Model is not converging.  Current: 13121.234198300472 is not greater than 13121.239950820192. Delta is -0.005752519720772398\n",
      "Model is not converging.  Current: 13121.235421431575 is not greater than 13121.23924133756. Delta is -0.0038199059854377992\n",
      "Model is not converging.  Current: 13463.031461219227 is not greater than 13463.093396163442. Delta is -0.06193494421495416\n",
      "Model is not converging.  Current: 13315.851916878188 is not greater than 13315.859576429619. Delta is -0.007659551431061118\n",
      "Model is not converging.  Current: 13463.06833941711 is not greater than 13463.070567932962. Delta is -0.0022285158520389814\n",
      "Model is not converging.  Current: 13315.851473588293 is not greater than 13315.858499756625. Delta is -0.007026168332231464\n",
      "Model is not converging.  Current: 13704.058601517845 is not greater than 13704.064791557661. Delta is -0.00619003981591959\n",
      "Model is not converging.  Current: 13529.881813829626 is not greater than 13529.896279148596. Delta is -0.014465318969087093\n",
      "Model is not converging.  Current: 13622.507266713284 is not greater than 13622.542640524904. Delta is -0.035373811619137996\n",
      "Model is not converging.  Current: 13559.241010036892 is not greater than 13559.332736270173. Delta is -0.09172623328049667\n",
      "Model is not converging.  Current: 13559.184286229603 is not greater than 13559.275283065886. Delta is -0.09099683628301136\n",
      "Model is not converging.  Current: 13596.253386994358 is not greater than 13596.26246765015. Delta is -0.009080655790967285\n",
      "Model is not converging.  Current: 13732.098743094904 is not greater than 13732.208773288065. Delta is -0.11003019316012796\n",
      "Model is not converging.  Current: 13732.106277962464 is not greater than 13732.20591851379. Delta is -0.0996405513251375\n",
      "Model is not converging.  Current: 13475.75489396396 is not greater than 13475.80264199011. Delta is -0.0477480261506571\n",
      "Model is not converging.  Current: 13475.730531832989 is not greater than 13475.758228534418. Delta is -0.027696701428794768\n",
      "Model is not converging.  Current: 13443.042146669197 is not greater than 13443.047069889788. Delta is -0.00492322059108119\n",
      "Model is not converging.  Current: 13443.043099432527 is not greater than 13443.04429657766. Delta is -0.001197145133119193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCS solver in static MVO failed, switching to ECOS: at least one of the assets must have an expected return exceeding the risk-free rate\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one of the assets must have an expected return exceeding the risk-free rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/var/folders/mg/4q2pl8qx47b43dbs_tncwchh0000gn/T/ipykernel_35634/2252095573.py\", line 22, in static_mvo_allocation\n  File \"/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/pypfopt/efficient_frontier/efficient_frontier.py\", line 245, in max_sharpe\n    raise ValueError(\nValueError: at least one of the assets must have an expected return exceeding the risk-free rate\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/mg/4q2pl8qx47b43dbs_tncwchh0000gn/T/ipykernel_35634/2391909717.py\", line 26, in single_monte_carlo_run\n  File \"/var/folders/mg/4q2pl8qx47b43dbs_tncwchh0000gn/T/ipykernel_35634/2391909717.py\", line 9, in run_scenario_123\n  File \"/var/folders/mg/4q2pl8qx47b43dbs_tncwchh0000gn/T/ipykernel_35634/4138739935.py\", line 107, in run_allocation\n  File \"/var/folders/mg/4q2pl8qx47b43dbs_tncwchh0000gn/T/ipykernel_35634/2252095573.py\", line 26, in static_mvo_allocation\n  File \"/Users/vlad/Desktop/git/anaconda3/lib/python3.12/site-packages/pypfopt/efficient_frontier/efficient_frontier.py\", line 245, in max_sharpe\n    raise ValueError(\nValueError: at least one of the assets must have an expected return exceeding the risk-free rate\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m T_sim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run parallel simulation\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m sharpe_data, all_metrics, all_runs, df_wilcoxon \u001b[38;5;241m=\u001b[39m run_monte_carlo_study(\n\u001b[1;32m      8\u001b[0m     n_runs\u001b[38;5;241m=\u001b[39mn_simulations,\n\u001b[1;32m      9\u001b[0m     T_sim\u001b[38;5;241m=\u001b[39mT_sim\n\u001b[1;32m     10\u001b[0m )\n",
      "Cell \u001b[0;32mIn[27], line 41\u001b[0m, in \u001b[0;36mrun_monte_carlo_study\u001b[0;34m(n_runs, T_sim)\u001b[0m\n\u001b[1;32m     38\u001b[0m n_cores \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_cores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m all_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_cores)(\n\u001b[1;32m     42\u001b[0m     delayed(single_monte_carlo_run)(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, T_sim) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs)\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Strategies\u001b[39;00m\n\u001b[1;32m     46\u001b[0m strategies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMVO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHMM-BL-Default\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHMM-BL-KMeans\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSJM-BL\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1748\u001b[0m \n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/git/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: at least one of the assets must have an expected return exceeding the risk-free rate"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: run 5 replications\n",
    "    n_simulations = 16\n",
    "    T_sim = 5000\n",
    "\n",
    "    # Run parallel simulation\n",
    "    sharpe_data, all_metrics, all_runs, df_wilcoxon = run_monte_carlo_study(\n",
    "        n_runs=n_simulations,\n",
    "        T_sim=T_sim\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
